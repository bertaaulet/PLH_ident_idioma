{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "168cc0fb",
   "metadata": {},
   "source": [
    "# Pràctica 1: Identificació d'Idioma\n",
    "**Assignatura:** Processament del Llenguatge Humà (PLH)  \n",
    "**Model:** Model de llenguatge basat en n-grames de caràcters \n",
    "\n",
    "## 1. Introducció\n",
    "L'objectiu d'aquesta pràctica és construir un classificador automàtic capaç d'assignar un idioma $l_i$ a un document $d$ d'entre un conjunt de 6 llengües europees: alemany (deu), anglès (eng), francès (fra), italià (ita), neerlandès (nld) i castellà (spa).\n",
    "\n",
    "El sistema es basa en la hipòtesi que les freqüències de certes seqüències de lletres (n-grames) són úniques per a cada idioma. En aquest cas, utilitzarem **trigrammes de caràcters** (n=3).\n",
    "\n",
    "### Recursos\n",
    "**Entrenament (Training):** 30.000 frases per idioma del corpus Wortschatz Leipzig.\n",
    "\n",
    "**Validació (Test):** 10.000 frases per idioma per avaluar la precisió (accuracy) i generar la matriu de confusió.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b007c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653b4b4b",
   "metadata": {},
   "source": [
    "## 2. Pas 1: Preprocessament del Text\n",
    "El text brut ha de ser normalitzat abans de l'entrenament per evitar biaixos causats per elements no lingüístics. \n",
    "\n",
    "### Procediment de neteja:\n",
    "1. **Eliminar els dígits**: S'eliminen els números del text, ja que no són informatius per identificar l'idioma.\n",
    "2. **Convertir a minúscula**: Es normalitzen tots els caràcters per reduir la dispersió de dades.\n",
    "3. **Substitució d'espais**: Es canvien els espais en blanc continus (o tabulacions) per un sol espai.\n",
    "4. **Unió de frases**: Es concatenen totes les frases del corpus inserint un **espai doble** entre elles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1d5dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguagePreprocessor:\n",
    "    def __init__(self, idiomes):\n",
    "        self.idiomes = idiomes\n",
    "\n",
    "    def clean_text(self, frases):\n",
    "        neteja = []\n",
    "        for linia in frases:\n",
    "            text = re.sub(r'\\d+', '', linia)\n",
    "            text = text.lower()\n",
    "            text = re.sub(r'\\s+', ' ', text).strip()\n",
    "            if text:\n",
    "                neteja.append(text)\n",
    "        return \"  \" + \"  \".join(neteja) + \"  \"\n",
    "\n",
    "    def process_files(self, tipus_fitxers=['trn', 'tst']):\n",
    "        for idioma in self.idiomes:\n",
    "            for tipus in tipus_fitxers:\n",
    "                nom_fitxer = f\"{idioma}_{tipus}.txt\"\n",
    "                if os.path.exists(nom_fitxer):\n",
    "                    print(f\"Processant {nom_fitxer}...\")\n",
    "                    with open(nom_fitxer, 'r', encoding='utf-8') as f:\n",
    "                        linies = f.readlines()\n",
    "                    text_net = self.clean_text(linies)\n",
    "                    nom_sortida = f\"{idioma}_{tipus}_clean.txt\"\n",
    "                    with open(nom_sortida, 'w', encoding='utf-8') as f_out:\n",
    "                        f_out.write(text_net)\n",
    "                    print(f\"Desat: {nom_sortida}\")\n",
    "\n",
    "    def obtenir_frases_netes(self, fitxer):\n",
    "        with open(fitxer, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        return [frase for frase in text.split(\"  \") if len(frase.strip()) > 0]\n",
    "\n",
    "# Execució del preprocessament\n",
    "idiomes = ['deu', 'eng', 'fra', 'ita', 'nld', 'spa'] \n",
    "preprocessor = LanguagePreprocessor(idiomes)\n",
    "preprocessor.process_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3948ccd9",
   "metadata": {},
   "source": [
    "## 3. Pas 2: Generació del Model i Filtratge amb NLTK\n",
    "\n",
    "Per a la construcció del model de llenguatge basat en caràcters, utilitzarem la llibreria **NLTK**, concretament la classe `TrigramCollocationFinder`.\n",
    "\n",
    "### Procediment:\n",
    "1. **Extracció de Trigrammes de caràcters:** Com que volem un model basat en caràcters, passarem l'string sencer (el text prèviament netejat) a la funció `from_words()`. D'aquesta manera, NLTK tractarà cada lletra i espai com una unitat bàsica, generant seqüències de 3 caràcters (ex: `('c', 'a', 's')`).\n",
    "2. **Filtratge de freqüències:** Per reduir el soroll estadístic i eliminar combinacions rares o errors, eliminem els trigrammes que apareguin menys de 5 vegades al corpus. Utilitzarem la funció nativa d'NLTK `apply_freq_filter(5)`.\n",
    "3. **Obtenció del diccionari:** Finalment, extreurem les freqüències filtrades mitjançant l'atribut `ngram_fd`, que ens retorna un diccionari de freqüències (FreqDist) llest per ser utilitzat en el càlcul de probabilitats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a212d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel:\n",
    "    def __init__(self, idiomes):\n",
    "        self.idiomes = idiomes\n",
    "        self.models_uni = {}\n",
    "        self.models_bi = {}\n",
    "        self.models_tri = {}\n",
    "        self.N_uni = {}\n",
    "        self.N_bi = {}\n",
    "        self.N_tri = {}\n",
    "        self.recomptes = {}\n",
    "        self.vocabulari_global = set()\n",
    "        self.B_global = 0\n",
    "\n",
    "    def train(self, data_dict):\n",
    "        \"\"\"\n",
    "        data_dict: dict amb format {idioma: string_amb_tot_el_text}\n",
    "        \"\"\"\n",
    "        self.vocabulari_global = set()\n",
    "        \n",
    "        for idioma in self.idiomes:\n",
    "            text_train = data_dict[idioma]\n",
    "            \n",
    "            # Models d'unigrames i bigrames\n",
    "            llista_chars = list(text_train)\n",
    "            self.models_uni[idioma] = nltk.FreqDist(llista_chars)\n",
    "            self.models_bi[idioma] = nltk.FreqDist(nltk.ngrams(llista_chars, 2))\n",
    "            \n",
    "            self.N_uni[idioma] = len(llista_chars)\n",
    "            self.N_bi[idioma] = len(llista_chars) - 1\n",
    "            \n",
    "            # Model principal de trigrames\n",
    "            finder = TrigramCollocationFinder.from_words(text_train)\n",
    "            \n",
    "            # Afegim tots els trigrames trobats al vocabulari global abans de filtrar\n",
    "            for trigramma in finder.ngram_fd.keys():\n",
    "                self.vocabulari_global.add(trigramma)\n",
    "                \n",
    "            # Apliquem el filtre de freqüència >= 5 \n",
    "            finder.apply_freq_filter(5)\n",
    "            model = finder.ngram_fd\n",
    "            \n",
    "            self.models_tri[idioma] = model\n",
    "            self.N_tri[idioma] = sum(model.values()) \n",
    "            self.recomptes[idioma] = len(model) \n",
    "            print(f\"Model per '{idioma}' generat amb èxit. Trigrammes únics: {len(model)}\")\n",
    "\n",
    "        # Càlcul de B global\n",
    "        self.B_global = len(self.vocabulari_global)\n",
    "        print(\"\\nTots els models d'entrenament han estat generats.\")\n",
    "\n",
    "    def _get_trigram_fd(self, frase):\n",
    "        finder = TrigramCollocationFinder.from_words(\"  \" + frase + \"  \")\n",
    "        return finder.ngram_fd\n",
    "\n",
    "    def calcul_probabilitat(self, frase, idioma, parametre, tecnica):\n",
    "        # Generem els trigrames de la frase\n",
    "        trigrames_frase = self._get_trigram_fd(frase)\n",
    "        \n",
    "        model3 = self.models_tri[idioma]\n",
    "        N = self.N_tri[idioma] \n",
    "        V = self.recomptes[idioma] \n",
    "        \n",
    "        log_p = 0.0\n",
    "        \n",
    "        for trig, freq in trigrames_frase.items():\n",
    "            c3 = model3.get(trig, 0)\n",
    "            \n",
    "            if tecnica == 'lidstone':\n",
    "                lamb = parametre\n",
    "                p = (c3 + lamb) / (N + self.B_global * lamb)\n",
    "                \n",
    "            elif tecnica == 'absolute_discounting':\n",
    "                delta = parametre\n",
    "                N0 = self.B_global - V \n",
    "                if c3 > 0:\n",
    "                    p = (c3 - delta) / N\n",
    "                else:\n",
    "                    p = ((self.B_global - N0) * delta / N0) / N\n",
    "                    \n",
    "            elif tecnica == 'interpolation':\n",
    "                lamb3, lamb2, lamb1 = parametre \n",
    "                w_n_2, w_n_1, w_n = trig\n",
    "\n",
    "                c2 = self.models_bi[idioma].get((w_n_2, w_n_1), 0)\n",
    "                p3 = c3 / c2 if c2 > 0 else 0\n",
    "                \n",
    "                c_bigrama = self.models_bi[idioma].get((w_n_1, w_n), 0)\n",
    "                c1 = self.models_uni[idioma].get(w_n_1, 0)\n",
    "                p2 = c_bigrama / c1 if c1 > 0 else 0\n",
    "                \n",
    "                c_unigrama = self.models_uni[idioma].get(w_n, 0)\n",
    "                p1 = c_unigrama / self.N_uni[idioma] if self.N_uni[idioma] > 0 else 0\n",
    "                \n",
    "                p = lamb1 * p1 + lamb2 * p2 + lamb3 * p3\n",
    "                \n",
    "            if p <= 0: \n",
    "                p = 1e-10 \n",
    "                \n",
    "            log_p += freq * math.log(p)\n",
    "            \n",
    "        return log_p\n",
    "\n",
    "# Prova d'entrenament simple per visualitzar el funcionament tal com es feia\n",
    "dades_train_simple = {}\n",
    "for idioma in idiomes:\n",
    "    fitxer_train = f\"{idioma}_trn_clean.txt\"\n",
    "    if os.path.exists(fitxer_train):\n",
    "        with open(fitxer_train, 'r', encoding='utf-8') as f:\n",
    "            dades_train_simple[idioma] = f.read()\n",
    "\n",
    "model_simple = LanguageModel(idiomes)\n",
    "if dades_train_simple:\n",
    "    model_simple.train(dades_train_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b416a2fc",
   "metadata": {},
   "source": [
    "## 4. Pas 3: Càlcul de Probabilitats i Tècniques de Suavitzat (Smoothing)\n",
    "\n",
    "Per calcular la probabilitat que un document de text pertanyi a un idioma determinat, utilitzem un model basat en n-grames assumint independència condicional (enfocament *Naive Bayes*). La probabilitat del document sencer s'estima com el producte de les probabilitats individuals de cada trigramma que el compon.\n",
    "\n",
    "El problema d'utilitzar l'estimació de Màxima Versemblança (MLE) és la dispersió de dades: assigna una probabilitat de zero als trigrammes no observats durant l'entrenament, la qual cosa anul·la automàticament la probabilitat de tota la frase. Per evitar-ho, utilitzarem i compararem **tres tècniques de suavitzat (smoothing)**.\n",
    "\n",
    "### 4.1. L'espai mostral i l'estimació de $B$\n",
    "\n",
    "Abans d'aplicar qualsevol fórmula, cal definir acuradament l'espai mostral. Totes les tècniques necessitaran el paràmetre **$B$**, que representa la mida del vocabulari, és a dir, el nombre de trigrammes *potencialment observables*.\n",
    "\n",
    "**Per què $B$ ha de ser global i igual per a tots els idiomes?**\n",
    "Si volem comparar de forma justa $P(text | anglès)$ i $P(text | francès)$ mitjançant un `argmax`, ambdós models han de basar-se en el mateix espai mostral. Si cada idioma tingués la seva pròpia $B$, les probabilitats estarien distribuïdes sobre espais de diferent mida i no serien matemàticament comparables.\n",
    "\n",
    "**Com estimem $B$?**\n",
    "Teòricament, $B$ podria ser totes les combinacions matemàtiques possibles de 3 caràcters (ex: $30^3 = 27.000$), però moltes d'aquestes combinacions no existeixen en cap idioma humà. D'altra banda, si calculem $B$ només amb els trigrammes filtrats (freq $\\ge 5$), estaríem subestimant la diversitat real de la llengua. \n",
    "Per tant, la millor estimació és la **unió de tots els trigrammes únics trobats en els corpus d'entrenament de tots els idiomes ABANS d'aplicar el filtre**. Això ens dona una constant $B$ global, realista i robusta per a totes les fórmules.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2. Les Tres Tècniques de Suavitzat\n",
    "\n",
    "En tots els models definirem **$N_T$** com la suma total de les freqüències dels trigrammes de l'idioma (després del filtre) i **$c_T(e_j)$** com la freqüència d'un trigramma específic.\n",
    "\n",
    "#### A) Llei de Lidstone\n",
    "Aquesta tècnica afegeix una petita quantitat constant $\\lambda$ a totes les observacions (vistes i no vistes) per evitar els zeros.\n",
    "\n",
    "$$P_{LID}(e_j) = \\frac{c_T(e_j) + \\lambda}{N_T + \\lambda \\cdot B}$$\n",
    "\n",
    "El paràmetre $\\lambda$ controla quanta \"massa de probabilitat\" traiem als trigrammes observats per repartir-la entre els desconeguts.\n",
    "\n",
    "#### B) Descompte Absolut (Absolute Discounting)\n",
    "En comptes d'afegir probabilitat a tot arreu, aquesta tècnica **resta una quantitat constant $\\alpha$** ($0 < \\alpha < 1$) a les freqüències dels trigrammes que sí que hem observat. La massa de probabilitat total \"robada\" és $\\alpha \\cdot V_T$ (on $V_T$ és el nombre de trigrammes únics de l'idioma). Aquesta massa es reparteix uniformement **només entre els trigrammes que no hem vist mai** (que són exactament $B - V_T$).\n",
    "\n",
    "* **Si el trigramma s'ha vist ($c_T(e_j) > 0$):**\n",
    "  $$P_{AD}(e_j) = \\frac{c_T(e_j) - \\alpha}{N_T}$$\n",
    "\n",
    "* **Si el trigramma NO s'ha vist ($c_T(e_j) = 0$):**\n",
    "  $$P_{AD}(e_j) = \\frac{\\frac{V_T \\cdot \\alpha}{B - V_T}}{N_T}$$\n",
    "\n",
    "#### C) Interpolació Lineal (Jelinek-Mercer)\n",
    "Aquesta tècnica construeix un model més robust combinant (interpolant) la probabilitat del trigrama amb les probabilitats d'ordre inferior (bigrames i unigrames). Si un trigrama no s'ha vist mai, el model es recolza en contextos més curts per no anul·lar la probabilitat.\n",
    "\n",
    "Donat un trigrama $e_j = (w_{i-2}, w_{i-1}, w_i)$:\n",
    "\n",
    "$$P_{INT}(d) \\approx \\lambda_0 \\cdot P(w_i, w_{i-1}, w_{i-2}) + \\lambda_1 \\cdot P(w_i, w_{i-1}) + \\lambda_2 \\cdot P(w_i)$$\n",
    "\n",
    "Amb la condició estricta que $\\lambda_0 + \\lambda_1 + \\lambda_2 = 1$. Els paràmetres $\\lambda$ indiquen el \"pes\" que atorguem a cada nivell d'informació (trigrama, bigrama i unigrama respectivament).\n",
    "\n",
    "---\n",
    "\n",
    "### 4.3. Selecció del Model via Validació Creuada (Cross-Validation)\n",
    "\n",
    "Assumir paràmetres a cegues no és rigorós. Per trobar la millor tècnica i el seu hiperparàmetre òptim, implementarem un procés de *Cross-Validation*:\n",
    "\n",
    "1. **Partició de dades:** Dividirem el corpus d'entrenament mitjançant *Hold-out Validation* (80% per entrenar, 20% per validar).\n",
    "2. **Entrenament:** Construirem els models de freqüències utilitzant exclusivament el 80% de les dades.\n",
    "3. **Avaluació (Grid Search):** Avaluarem l'exactitud (*accuracy*) en el 20% de validació provant les 3 tècniques amb diferents bateries de valors per als seus paràmetres ($\\lambda$ per Lidstone, $\\alpha$ per Descompte Absolut i conjunts de tuples $\\lambda_n$ per Interpolació).\n",
    "4. **Selecció Final:** Ens quedarem amb el mètode i el paràmetre que assoleixi el millor percentatge d'encerts globals per utilitzar-lo, posteriorment, amb les dades de Test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf93104a",
   "metadata": {},
   "source": [
    "## 4. Pas 3: Càlcul de Probabilitats i Tècniques de Suavitzat (Smoothing)\n",
    "\n",
    "Per calcular la probabilitat que un document de text pertanyi a un idioma determinat, utilitzem un model basat en n-grames assumint independència condicional (enfocament *Naive Bayes*). Com que treballem amb probabilitats molt petites, calculem la **log-probabilitat** sumant els logaritmes de cada n-grama per evitar el subdesbordament aritmètic (*underflow*) de l'ordinador.\n",
    "\n",
    "El problema d'utilitzar l'estimació de Màxima Versemblança (MLE) és la dispersió de dades: assigna una probabilitat de zero als trigrammes no observats durant l'entrenament, la qual cosa anul·la automàticament la probabilitat de tota la frase. Per evitar-ho, utilitzarem i compararem **tres tècniques de suavitzat (smoothing)**.\n",
    "\n",
    "### 4.1. L'espai mostral i l'estimació de $B$\n",
    "\n",
    "Abans d'aplicar qualsevol fórmula, cal definir acuradament l'espai mostral. Totes les tècniques necessitaran el paràmetre **$B$**, que representa el nombre de valors potencialment observables per a l'n-grama.\n",
    "\n",
    "**Per què $B$ ha de ser global i igual per a tots els idiomes?**\n",
    "Si volem comparar de forma justa $P(text | anglès)$ i $P(text | francès)$ mitjançant un `argmax`, ambdós models han de basar-se en el mateix espai mostral. Si cada idioma tingués la seva pròpia $B$, les probabilitats estarien distribuïdes sobre espais de diferent mida i no serien matemàticament comparables.\n",
    "\n",
    "**Com estimem $B$?**\n",
    "Teòricament, $B$ podria ser totes les combinacions matemàtiques possibles de 3 caràcters. No obstant això, la millor estimació és la **unió de tots els trigrammes únics trobats en els corpus d'entrenament de tots els idiomes ABANS d'aplicar el filtre**. Això ens dona una constant $B$ global, realista i robusta.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2. Consideracions sobre els denominadors ($N$)\n",
    "\n",
    "S'ha optat per una **metodologia asimètrica** en el càlcul del nombre total d'observacions ($N$) segons el nivell del model:\n",
    "\n",
    "* **Models d'unigrames i bigrames:** En aquests nivells, $N_{uni}$ i $N_{bi}$ representen la totalitat dels caràcters del corpus d'entrenament. No s'aplica cap filtre per garantir que la \"xarxa de seguretat\" de la interpolació estigui completa.\n",
    "* **Model de trigrames ($N_{tri}$):** Es calcula com la suma de les freqüències **posteriors al filtratge** ($\\ge 5$). Això assegura que la probabilitat es reparteixi exclusivament entre esdeveniments significatius, evitant diluir-la cap a combinacions descartades per soroll.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.3. Les Tres Tècniques de Suavitzat\n",
    "\n",
    "En les següents fórmules, $C(w_{1}...w_{n})$ representa la freqüència d'un n-grama específic en el model d'entrenament.\n",
    "\n",
    "#### A) Llei de Lidstone\n",
    "[cite_start]Aquesta tècnica afegeix una quantitat constant $\\lambda$ (on $\\lambda < 1$) als recomptes de totes les observacions[cite: 13]. Això roba una mica de \"massa de probabilitat\" als trigrammes observats per repartir-la entre els desconeguts.\n",
    "\n",
    "[cite_start]$$P_{LID}(w_1...w_n) = \\frac{C(w_1...w_n) + \\lambda}{N_{tri} + B \\lambda}$$ [cite: 19]\n",
    "\n",
    "#### B) Descompte Absolut (Absolute Discounting)\n",
    "[cite_start]En comptes d'afegir probabilitat a tot arreu, aquesta tècnica **resta una quantitat constant $\\delta$** ($0 < \\delta < 1$) a les freqüències dels trigrammes que sí que hem observat[cite: 35]. Aquesta massa es reparteix uniformement **només entre els trigrammes que no hem vist mai**.\n",
    "\n",
    "[cite_start]Per a aquesta fórmula definim $N_0$ com el nombre de possibles valors observats 0 vegades[cite: 40]. A la pràctica, es calcula com $N_0 = B - V$, on $V$ són els trigrammes únics vistos en l'idioma.\n",
    "\n",
    "* **Si el trigramma s'ha vist ($C(w_1...w_n) > 0$):**\n",
    "  [cite_start]$$P_{ABS}(w_1...w_n) = \\frac{C(w_1...w_n) - \\delta}{N_{tri}}$$ [cite: 41]\n",
    "\n",
    "* **Si el trigramma NO s'ha vist (altrament):**\n",
    "  [cite_start]$$P_{ABS}(w_1...w_n) = \\frac{(B - N_0)\\delta / N_0}{N_{tri}}$$ [cite: 41]\n",
    "\n",
    "#### C) Interpolació Lineal\n",
    "Aquesta tècnica construeix un model més robust combinant (interpolant) la probabilitat condicionada del trigrama amb les probabilitats condicionades d'ordre inferior (bigrames i unigrames). Si un trigrama no s'ha vist mai en un context determinat, el model es recolza en la probabilitat del caràcter en contextos més curts per evitar anul·lar la probabilitat final.\n",
    "\n",
    "La fórmula de la combinació lineal per a un trigrama compost pels caràcters $(w_{n-2}, w_{n-1}, w_n)$ és:\n",
    "\n",
    "$$P_{LI}(w_n | w_{n-2}, w_{n-1}) = \\lambda_3 \\cdot P_3(w_n | w_{n-2}, w_{n-1}) + \\lambda_2 \\cdot P_2(w_n | w_{n-1}) + \\lambda_1 \\cdot P_1(w_n)$$\n",
    "\n",
    "On cada probabilitat s'estima mitjançant Màxima Versemblança (MLE) dividint la freqüència de l'n-grama per la freqüència del seu context històric (excepte en l'unigrama, que es divideix pel total de caràcters):\n",
    "\n",
    "* **Trigrama:** $P_3(w_n | w_{n-2}, w_{n-1}) = \\frac{C(w_{n-2}, w_{n-1}, w_n)}{C(w_{n-2}, w_{n-1})}$\n",
    "* **Bigrama:** $P_2(w_n | w_{n-1}) = \\frac{C(w_{n-1}, w_n)}{C(w_{n-1})}$\n",
    "* **Unigrama:** $P_1(w_n) = \\frac{C(w_n)}{N_{uni}}$\n",
    "\n",
    "Tot això sota la condició estricta que $\\lambda_3 + \\lambda_2 + \\lambda_1 = 1$. Els paràmetres $\\lambda$ indiquen el \"pes\" relatiu que atorguem a cada nivell d'informació.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.4. Selecció del Model via Validació Creuada (Cross-Validation)\n",
    "\n",
    "Assumir paràmetres a cegues no és rigorós. Per trobar la millor tècnica i el seu hiperparàmetre òptim, implementarem un procés de *Cross-Validation*:\n",
    "\n",
    "1. **Partició de dades:** Dividirem el corpus d'entrenament mitjançant *Hold-out Validation* (80% per entrenar, 20% per validar).\n",
    "2. **Entrenament:** Construirem els models de freqüències utilitzant exclusivament el 80% de les dades.\n",
    "3. **Avaluació:** Avaluarem l'exactitud (*accuracy*) en el 20% de validació provant les 3 tècniques amb diferents bateries de valors per als seus paràmetres ($\\lambda$ per Lidstone, $\\delta$ per Descompte Absolut i conjunts de tuples $\\lambda_n$ per Interpolació).\n",
    "4. **Selecció Final:** Ens quedarem amb el mètode i el paràmetre que assoleixi el millor percentatge d'encerts globals per utilitzar-lo, posteriorment, amb les dades de Test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee0f45a",
   "metadata": {},
   "source": [
    "### Consideracions sobre els denominadors ($N$)\n",
    "\n",
    "S'ha optat per una metodologia asimètrica en el càlcul del nombre total de mostres ($N$) segons el nivell del model. Per als models d'unigrames i bigrames, $N$ representa la totalitat dels caràcters del corpus, garantint que la xarxa de seguretat de la interpolació sigui completa. \n",
    "\n",
    "En canvi, per al model de trigrames, $N_{tri}$ es calcula com la suma de les freqüències **posteriors al filtratge** ($\\ge 5$). Aquesta decisió assegura que la distribució de probabilitat es reparteixi exclusivament entre els esdeveniments que el model considera significatius, evitant una dilució artificial de la probabilitat cap a combinacions que han estat descartades per soroll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fdb7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageEvaluator:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, frase, tecnica, parametre):\n",
    "        max_prob = -float('inf')\n",
    "        idioma_predit = None\n",
    "        \n",
    "        for idioma_model in self.model.idiomes:\n",
    "            prob = self.model.calcul_probabilitat(frase, idioma_model, parametre, tecnica)\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                idioma_predit = idioma_model\n",
    "                \n",
    "        return idioma_predit\n",
    "\n",
    "    def cross_validation(self, dades_val, proves):\n",
    "        resultats_cv = {}\n",
    "        \n",
    "        for tecnica, llista_parametres in proves.items():\n",
    "            print(f\"--- Avaluant tècnica: {tecnica.upper()} ---\")\n",
    "            millor_acc_tecnica = 0.0\n",
    "            millor_param_tecnica = None\n",
    "            \n",
    "            for param in llista_parametres:\n",
    "                encerts = 0\n",
    "                total_frases = 0\n",
    "                \n",
    "                for idioma_real, llista_frases in dades_val.items():\n",
    "                    for frase in llista_frases:\n",
    "                        total_frases += 1\n",
    "                        idioma_predit = self.predict(frase, tecnica, param)\n",
    "                        \n",
    "                        if idioma_predit == idioma_real:\n",
    "                            encerts += 1\n",
    "                            \n",
    "                accuracy = encerts / total_frases\n",
    "                print(f\"  Param={str(param):<15} -> Accuracy: {accuracy:.4f}\")\n",
    "                \n",
    "                if accuracy > millor_acc_tecnica:\n",
    "                    millor_acc_tecnica = accuracy\n",
    "                    millor_param_tecnica = param\n",
    "                    \n",
    "            resultats_cv[tecnica] = {'param': millor_param_tecnica, 'acc': millor_acc_tecnica}\n",
    "            print(f\"  >> Guanyador {tecnica}: Param={millor_param_tecnica} (Acc={millor_acc_tecnica:.4f})\\n\")\n",
    "            \n",
    "        millor_tecnica_global = None\n",
    "        millor_acc_global = 0.0\n",
    "\n",
    "        for tec, res in resultats_cv.items():\n",
    "            if res['acc'] > millor_acc_global:\n",
    "                millor_acc_global = res['acc']\n",
    "                millor_tecnica_global = tec\n",
    "\n",
    "        print(f\"\\nLa millor tècnica és: {millor_tecnica_global.upper()} amb un accuracy de {millor_acc_global:.4f}\")\n",
    "        return resultats_cv, millor_tecnica_global, millor_acc_global\n",
    "\n",
    "    def avaluar_test(self, dades_test, tecnica, parametre):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        \n",
    "        for idioma_real, frases in dades_test.items():\n",
    "            for frase in frases:\n",
    "                y_true.append(idioma_real)\n",
    "                idioma_predit = self.predict(frase, tecnica, parametre)\n",
    "                y_pred.append(idioma_predit)\n",
    "                \n",
    "        acc_final = accuracy_score(y_true, y_pred)\n",
    "        print(f\"\\nResultat Final\")\n",
    "        print(f\"Accuracy en Test: {acc_final:.4f} ({int(acc_final * len(y_true))}/{len(y_true)} encerts)\")\n",
    "        \n",
    "        cm = confusion_matrix(y_true, y_pred, labels=self.model.idiomes)\n",
    "        df_cm = pd.DataFrame(cm, index=self.model.idiomes, columns=self.model.idiomes)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "        plt.title(f'Matriu de Confusió ({tecnica} {str(parametre)}) - Acc: {acc_final:.4f}')\n",
    "        plt.ylabel('Idioma Real')\n",
    "        plt.xlabel('Idioma Predit')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nMatriu de Confusió (Text):\")\n",
    "        print(df_cm)\n",
    "        return y_true, y_pred, df_cm\n",
    "\n",
    "    def mostrar_trigrames_dominants(self, idioma, top_n=10):\n",
    "        scores = {}\n",
    "        model_actual = self.model.models_tri[idioma]\n",
    "        \n",
    "        for trig, freq in model_actual.items():\n",
    "            altres_freq = sum(self.model.models_tri[i].get(trig, 0) for i in self.model.idiomes if i != idioma)\n",
    "            scores[trig] = freq / (altres_freq + 1)\n",
    "            \n",
    "        millors = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        \n",
    "        print(f\"Trigrames més identitaris del '{idioma}':\")\n",
    "        for t, s in millors:\n",
    "            print(f\"  {''.join(t)} (Score: {s:.2f})\")\n",
    "\n",
    "# PARTICIÓ DE DADES PER A CROSS-VALIDATION\n",
    "dades_train_cv = {}\n",
    "dades_val_cv = {}\n",
    "\n",
    "for idioma in idiomes:\n",
    "    fitxer_train = f\"{idioma}_trn_clean.txt\"\n",
    "    if os.path.exists(fitxer_train):\n",
    "        frases = preprocessor.obtenir_frases_netes(fitxer_train)\n",
    "        divisio = int(len(frases) * 0.8)\n",
    "        text_train = \"  \" + \"  \".join(frases[:divisio]) + \"  \"\n",
    "        \n",
    "        dades_train_cv[idioma] = text_train\n",
    "        dades_val_cv[idioma] = frases[divisio:]\n",
    "\n",
    "model_cv = LanguageModel(idiomes)\n",
    "if dades_train_cv:\n",
    "    model_cv.train(dades_train_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5887904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquesta secció s'ha integrat completament en LanguageEvaluator a dalt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24660707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMITZACIÓ: CROSS-VALIDATION\n",
    "proves = {\n",
    "    'lidstone': [0.01, 0.1, 0.25, 0.5, 0.75, 1.0],\n",
    "    'absolute_discounting': [0.1, 0.5, 0.75, 0.9],\n",
    "    'interpolation': [\n",
    "        (0.6, 0.3, 0.1),\n",
    "        (0.7, 0.2, 0.1), \n",
    "        (0.8, 0.15, 0.05), \n",
    "        (0.5, 0.4, 0.1)\n",
    "    ]\n",
    "}\n",
    "\n",
    "if dades_train_cv:\n",
    "    evaluator_cv = LanguageEvaluator(model_cv)\n",
    "    resultats_cv, millor_tec, millor_acc = evaluator_cv.cross_validation(dades_val_cv, proves)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef25763",
   "metadata": {},
   "source": [
    "## 5. Pas 4: Avaluació Final i Matriu de Confusió\n",
    "\n",
    "Després d'executar la validació creuada sobre el conjunt d'entrenament, hem determinat que la millor tècnica de suavitzat per a les nostres dades és la **Llei de Lidstone amb un paràmetre $\\lambda = 0.75$**, assolint una precisió superior al 99.8%.\n",
    "\n",
    "En aquesta fase final, procedim a avaluar el rendiment real del classificador sobre dades mai vistes.\n",
    "\n",
    "### 5.1. Entrenament del Model Definitiu\n",
    "Per aprofitar tot el coneixement disponible, construïm els models de llenguatge definitius utilitzant el **100% del corpus d'entrenament** (`_trn_clean.txt`) per a cada idioma, aplicant el filtre de freqüència $\\ge 5$ i calculant la constant global $B$ amb tots els trigrammes previs al filtratge.\n",
    "\n",
    "### 5.2. Avaluació sobre el Test Set\n",
    "El conjunt de prova consta de 10.000 frases per idioma (`_tst_clean.txt`). Cada frase serà avaluada pels 6 models d'idioma, i se li assignarà l'idioma que maximitzi la probabilitat (utilitzant la fórmula de Lidstone optimitzada).\n",
    "\n",
    "### 5.3. Matriu de Confusió\n",
    "Per entendre millor els errors del model, generarem una **Matriu de Confusió**. Aquesta taula ens permetrà analitzar les classificacions incorrectes i veure si hi ha confusió sistemàtica entre llengües morfològicament properes (com el francès, l'espanyol i l'italià, o l'anglès, l'alemany i el neerlandès)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9cdbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pas 4: Avaluació Final - Construint els models definitius (100% Train)\n",
    "dades_train_full = {}\n",
    "dades_test = {}\n",
    "\n",
    "for idioma in idiomes:\n",
    "    fitxer_train = f\"{idioma}_trn_clean.txt\"\n",
    "    if os.path.exists(fitxer_train):\n",
    "        with open(fitxer_train, 'r', encoding='utf-8') as f:\n",
    "            dades_train_full[idioma] = f.read()\n",
    "            \n",
    "    fitxer_test = f\"{idioma}_tst_clean.txt\"\n",
    "    if os.path.exists(fitxer_test):\n",
    "        dades_test[idioma] = preprocessor.obtenir_frases_netes(fitxer_test)\n",
    "\n",
    "model_definitiu = LanguageModel(idiomes)\n",
    "if dades_train_full:\n",
    "    model_definitiu.train(dades_train_full)\n",
    "\n",
    "print(f\"B Global Definitiva: {model_definitiu.B_global} trigrammes únics.\")\n",
    "\n",
    "evaluator = LanguageEvaluator(model_definitiu)\n",
    "\n",
    "# Avaluant sobre el conjunt de Test (Lidstone 0.75)\n",
    "if dades_test:\n",
    "    print(\"Avaluant sobre el conjunt de Test (Lidstone 0.75)...\")\n",
    "    _, _, _ = evaluator.avaluar_test(dades_test, 'lidstone', 0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c195c7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaluant sobre el conjunt de Test (Interpolació)\n",
    "if dades_test:\n",
    "    print(\"Avaluant sobre el conjunt de Test (Interpolació 0.8, 0.15, 0.05)...\")\n",
    "    _, _, _ = evaluator.avaluar_test(dades_test, 'interpolation', (0.8, 0.15, 0.05))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9046084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigrames dominants\n",
    "if dades_train_full:\n",
    "    evaluator.mostrar_trigrames_dominants('eng')\n",
    "    print(\"-\" * 30)\n",
    "    evaluator.mostrar_trigrames_dominants('deu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a094afda",
   "metadata": {},
   "source": [
    "## Avaluació Global del Rendiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62304029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_trigrames_dominants(idioma, top_n=10):\n",
    "    # Calculem la relació de freqüència: freq en aquest idioma / suma de freq en els altres\n",
    "    # Això ens indica quins trigrames són \"únics\" o molt identitaris\n",
    "    scores = {}\n",
    "    model_actual = models_tri_def[idioma]\n",
    "    \n",
    "    for trig, freq in model_actual.items():\n",
    "        # Sumem la freqüència d'aquest trigrama en la resta d'idiomes\n",
    "        altres_freq = sum(models_tri_def[i].get(trig, 0) for i in idiomes if i != idioma)\n",
    "        # Score: Freqüència relativa vs resta (evitant divisió per zero)\n",
    "        scores[trig] = freq / (altres_freq + 1)\n",
    "        \n",
    "    # Ordenem pels millors scores\n",
    "    millors = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    \n",
    "    print(f\"Trigrames més identitaris del '{idioma}':\")\n",
    "    for t, s in millors:\n",
    "        print(f\"  {''.join(t)} (Score: {s:.2f})\")\n",
    "\n",
    "# Exemple per a dos idiomes\n",
    "mostrar_trigrames_dominants('eng')\n",
    "print(\"-\" * 30)\n",
    "mostrar_trigrames_dominants('deu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_PLH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
