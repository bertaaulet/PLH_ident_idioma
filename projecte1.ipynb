{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "168cc0fb",
   "metadata": {},
   "source": [
    "# Pràctica 1: Identificació d'Idioma\n",
    "**Assignatura:** Processament del Llenguatge Humà (PLH)  \n",
    "**Model:** Model de llenguatge basat en n-grames de caràcters \n",
    "\n",
    "## 1. Introducció\n",
    "L'objectiu d'aquesta pràctica és construir un classificador automàtic capaç d'assignar un idioma $l_i$ a un document $d$ d'entre un conjunt de 6 llengües europees: alemany (deu), anglès (eng), francès (fra), italià (ita), neerlandès (nld) i castellà (spa).\n",
    "\n",
    "El sistema es basa en la hipòtesi que les freqüències de certes seqüències de lletres (n-grames) són úniques per a cada idioma. En aquest cas, utilitzarem **trigrammes de caràcters** (n=3).\n",
    "\n",
    "### Recursos\n",
    "**Entrenament (Training):** 30.000 frases per idioma del corpus Wortschatz Leipzig.\n",
    "\n",
    "**Validació (Test):** 10.000 frases per idioma per avaluar la precisió (accuracy) i generar la matriu de confusió.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Pas 1: Preprocessament del Text\n",
    "El text brut ha de ser normalitzat abans de l'entrenament per evitar biaixos causats per elements no lingüístics. \n",
    "\n",
    "### Procediment de neteja:\n",
    "1. **Eliminar els dígits**: S'eliminen els números del text, ja que no són informatius per identificar l'idioma.\n",
    "2. **Convertir a minúscula**: Es normalitzen tots els caràcters per reduir la dispersió de dades.\n",
    "3. **Substitució d'espais**: Es canvien els espais en blanc continus (o tabulacions) per un sol espai.\n",
    "4. **Unió de frases**: Es concatenen totes les frases del corpus inserint un **espai doble** entre elles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1d5dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processant deu_trn.txt...\n",
      "Desat: deu_trn_clean.txt\n",
      "Processant deu_tst.txt...\n",
      "Desat: deu_tst_clean.txt\n",
      "Processant eng_trn.txt...\n",
      "Desat: eng_trn_clean.txt\n",
      "Processant eng_tst.txt...\n",
      "Desat: eng_tst_clean.txt\n",
      "Processant fra_trn.txt...\n",
      "Desat: fra_trn_clean.txt\n",
      "Processant fra_tst.txt...\n",
      "Desat: fra_tst_clean.txt\n",
      "Processant ita_trn.txt...\n",
      "Desat: ita_trn_clean.txt\n",
      "Processant ita_tst.txt...\n",
      "Desat: ita_tst_clean.txt\n",
      "Processant nld_trn.txt...\n",
      "Desat: nld_trn_clean.txt\n",
      "Processant nld_tst.txt...\n",
      "Desat: nld_tst_clean.txt\n",
      "Processant spa_trn.txt...\n",
      "Desat: spa_trn_clean.txt\n",
      "Processant spa_tst.txt...\n",
      "Desat: spa_tst_clean.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def preprocess_text(frases):\n",
    "    \"\"\"\n",
    "    Neteja del text:\n",
    "    - Elimina dígits.\n",
    "    - Minúscules.\n",
    "    - Normalitza espais.\n",
    "    - Concatena amb espai doble al mig, i també a l'inici i al final.\n",
    "    \"\"\"\n",
    "    neteja = []\n",
    "\n",
    "    for linia in frases:\n",
    "        # 1. Eliminar els dígits\n",
    "        text = re.sub(r'\\d+', '', linia)\n",
    "        # 2. Convertir a minúscules \n",
    "        text = text.lower()\n",
    "        # 3. Substituir espais blancs continus per un de sol\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        if text:\n",
    "            neteja.append(text)\n",
    "    \n",
    "    # 4. Concatena les frases amb un espai doble al mig, a l'inici i al final\n",
    "    return \"  \" + \"  \".join(neteja) + \"  \"\n",
    "\n",
    "# Llista d'idiomes\n",
    "idiomes = ['deu', 'eng', 'fra', 'ita', 'nld', 'spa'] \n",
    "\n",
    "for lang in idiomes:\n",
    "    for tipus in ['trn', 'tst']:\n",
    "        nom_fitxer = f\"{lang}_{tipus}.txt\"\n",
    "        \n",
    "        if os.path.exists(nom_fitxer):\n",
    "            print(f\"Processant {nom_fitxer}...\")\n",
    "            with open(nom_fitxer, 'r', encoding='utf-8') as f:\n",
    "                linies = f.readlines()\n",
    "            \n",
    "            text_net = preprocess_text(linies)\n",
    "            \n",
    "            # Guardem el resultat en un fitxer nou\n",
    "            nom_sortida = f\"{lang}_{tipus}_clean.txt\"\n",
    "            with open(nom_sortida, 'w', encoding='utf-8') as f_out:\n",
    "                f_out.write(text_net)\n",
    "            print(f\"Desat: {nom_sortida}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3948ccd9",
   "metadata": {},
   "source": [
    "## 3. Pas 2: Generació del Model i Filtratge amb NLTK\n",
    "\n",
    "Per a la construcció del model de llenguatge basat en caràcters, utilitzarem la llibreria **NLTK**, concretament la classe `TrigramCollocationFinder`.\n",
    "\n",
    "### Procediment:\n",
    "1. **Extracció de Trigrammes de caràcters:** Com que volem un model basat en caràcters, passarem l'string sencer (el text prèviament netejat) a la funció `from_words()`. D'aquesta manera, NLTK tractarà cada lletra i espai com una unitat bàsica, generant seqüències de 3 caràcters (ex: `('c', 'a', 's')`).\n",
    "2. **Filtratge de freqüències:** Per reduir el soroll estadístic i eliminar combinacions rares o errors, eliminem els trigrammes que apareguin menys de 5 vegades al corpus. Utilitzarem la funció nativa d'NLTK `apply_freq_filter(5)`.\n",
    "3. **Obtenció del diccionari:** Finalment, extreurem les freqüències filtrades mitjançant l'atribut `ngram_fd`, que ens retorna un diccionari de freqüències (FreqDist) llest per ser utilitzat en el càlcul de probabilitats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a212d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciant la creació dels models de llenguatge...\n",
      "Model per 'deu' generat amb èxit. Trigrammes únics: 11321\n",
      "Model per 'eng' generat amb èxit. Trigrammes únics: 9390\n",
      "Model per 'fra' generat amb èxit. Trigrammes únics: 10421\n",
      "Model per 'ita' generat amb èxit. Trigrammes únics: 8325\n",
      "Model per 'nld' generat amb èxit. Trigrammes únics: 10148\n",
      "Model per 'spa' generat amb èxit. Trigrammes únics: 9294\n",
      "\n",
      "Tots els models d'entrenament han estat generats i emmagatzemats a 'models_entrenament'.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "\n",
    "# Diccionari global per emmagatzemar la freqüència dels trigrammes de cada idioma\n",
    "models_entrenament = {}\n",
    "\n",
    "idiomes = ['deu', 'eng', 'fra', 'ita', 'nld', 'spa']\n",
    "\n",
    "print(\"Iniciant la creació dels models de llenguatge...\")\n",
    "\n",
    "for lang in idiomes:\n",
    "    nom_fitxer_train = f\"{lang}_trn_clean.txt\"\n",
    "    \n",
    "    # Llegim el fitxer de text netejat d'entrenament\n",
    "    with open(nom_fitxer_train, 'r', encoding='utf-8') as f:\n",
    "        text_net = f.read()\n",
    "    \n",
    "    # 1. Generem els trigrammes de caràcters utilitzant NLTK\n",
    "    # NLTK genera tuples de 3 caràcters: ex. ('t', 'h', 'e')\n",
    "    finder = TrigramCollocationFinder.from_words(text_net)\n",
    "    \n",
    "    # 2. Apliquem el filtre per eliminar els trigrammes amb freqüència < 5\n",
    "    finder.apply_freq_filter(5)\n",
    "    \n",
    "    # 3. Guardem la distribució de freqüències (FreqDist) al nostre diccionari\n",
    "    models_entrenament[lang] = finder.ngram_fd\n",
    "    \n",
    "    # Imprimim informació per validar que s'ha creat correctament\n",
    "    num_trigrames = len(models_entrenament[lang])\n",
    "    print(f\"Model per '{lang}' generat amb èxit. Trigrammes únics: {num_trigrames}\")\n",
    "\n",
    "print(\"\\nTots els models d'entrenament han estat generats i emmagatzemats a 'models_entrenament'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce55711",
   "metadata": {},
   "source": [
    "## 4. Pas 3: Suavitzat de Lidstone per a N-grames\n",
    "\n",
    "Per calcular la probabilitat que un text pertanyi a un idioma determinat, utilitzem el model de probabilitat d'n-grames assumint independència condicional (enfocament *Naive Bayes*). La probabilitat del document sencer és el producte de les probabilitats individuals de cada trigramma que el compon.\n",
    "\n",
    "Com que el mètode de Màxima Versemblança (MLE) assigna probabilitat zero als trigrammes no observats durant l'entrenament, utilitzem la **Llei de Lidstone**.\n",
    "\n",
    "$$P_{LID}(trigramma | idioma) = \\frac{c(trigramma) + \\lambda}{N_{idioma} + \\lambda \\cdot B}$$\n",
    "\n",
    "### 4.1. L'espai mostral i el paràmetre $B$\n",
    "El paràmetre $B$ representa la mida del vocabulari, és a dir, el nombre de trigrammes *potencialment observables*. \n",
    "\n",
    "**Per què $B$ ha de ser igual per a tots els idiomes?**\n",
    "Si volem comparar de forma justa $P(text | anglès)$ i $P(text | francès)$, ambdós models han de basar-se en el **mateix espai mostral d'esdeveniments**. Si l'anglès tingués una $B$ de 2.000 i el francès una $B$ de 3.000, les probabilitats estarien distribuïdes sobre espais de diferent mida i no serien comparables.\n",
    "\n",
    "**Com estimem $B$?**\n",
    "Teòricament, $B$ podria ser totes les combinacions matemàtiques possibles de 3 caràcters (ex: si tenim un alfabet de 30 lletres i espais, $30^3 = 27.000$). No obstant això, moltes d'aquestes combinacions (com 'qqq' o 'zxw') no existeixen en cap idioma humà real. \n",
    "La millor estimació de l'espai mostral real és la **unió de tots els trigrammes únics trobats en els corpus d'entrenament de tots els idiomes junts**. Aquesta serà la nostra $B$ global i constant.\n",
    "\n",
    "### 4.2. Optimització de $\\lambda$ amb Cross-Validation (Validació Creuada)\n",
    "El paràmetre $\\lambda$ controla quant de \"pes\" traiem als trigrammes observats per repartir-lo entre els no observats. Assumir $\\lambda = 0.5$ (Regla de Jeffrey) o $\\lambda = 1$ (Regla de Laplace) sense proves no és òptim.\n",
    "\n",
    "Utilitzarem **Cross-Validation**:\n",
    "1. Dividirem el nostre corpus d'entrenament en dues parts: un sub-conjunt d'entrenament (ex: 80%) i un de validació (20%).\n",
    "2. Entrenarem el model només amb el 80%.\n",
    "3. Avaluarem l'exactitud (*accuracy*) en el 20% de validació utilitzant diferents valors de $\\lambda$ (ex: 0.01, 0.1, 0.2, 0.5, 1.0).\n",
    "4. Ens quedarem amb el $\\lambda$ que assoleixi el millor percentatge d'encerts per utilitzar-lo en el test final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaada39",
   "metadata": {},
   "source": [
    "te sentit fer mateixa b totes les llengues per aixi poder comparar, explicarlo bien lo de todas las combinaciones..., justificarlo bien ya que es una estimacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e41d3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mida del vocabulari global estimat (B): 20366 trigrammes.\n",
      "\n",
      "Iniciant Cross-Validation per trobar el millor lambda...\n",
      "Lambda: 0.001 -> Accuracy Validació: 0.9976 (35888/35973)\n",
      "Lambda: 0.01 -> Accuracy Validació: 0.9981 (35903/35973)\n",
      "Lambda: 0.1 -> Accuracy Validació: 0.9982 (35909/35973)\n",
      "Lambda: 0.2 -> Accuracy Validació: 0.9983 (35911/35973)\n",
      "Lambda: 0.5 -> Accuracy Validació: 0.9984 (35916/35973)\n",
      "Lambda: 1.0 -> Accuracy Validació: 0.9984 (35917/35973)\n",
      "\n",
      "EL MILLOR LAMBDA ÉS: 1.0 amb un accuracy de 0.9984\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "\n",
    "# Suposem que llegim el text net que vas guardar, separant per frases (amb el doble espai)\n",
    "def obtenir_frases_netes(fitxer):\n",
    "    with open(fitxer, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    # Separem pel doble espai que vam introduir al preprocés per recuperar les frases\n",
    "    # i eliminem elements buits\n",
    "    return [frase for frase in text.split(\"  \") if len(frase.strip()) > 0]\n",
    "\n",
    "# 1. Separació Train/Validació (80/20) i creació de models\n",
    "idiomes = ['deu', 'eng', 'fra', 'ita', 'nld', 'spa']\n",
    "dades_train = {}\n",
    "dades_val = {}\n",
    "models_cv = {} # Models entrenats només amb el 80%\n",
    "N_T_cv = {}    # Nombre total de trigrammes (freqüències) del 80%\n",
    "\n",
    "vocabulari_global_cv = set() # Per estimar la B\n",
    "\n",
    "for lang in idiomes:\n",
    "    fitxer = f\"{lang}_trn_clean.txt\"\n",
    "    frases = obtenir_frases_netes(fitxer)\n",
    "    \n",
    "    # Punt de tall: 80% entrenament, 20% validació\n",
    "    tall = int(len(frases) * 0.8)\n",
    "    dades_train[lang] = \"  \" + \"  \".join(frases[:tall]) + \"  \"\n",
    "    dades_val[lang] = frases[tall:] # Llista de frases per validar\n",
    "    \n",
    "    # Creem el model NLTK per al 80%\n",
    "    finder = TrigramCollocationFinder.from_words(dades_train[lang])\n",
    "    finder.apply_freq_filter(5) # Apliquem el filtre de classe\n",
    "    model = finder.ngram_fd\n",
    "    \n",
    "    models_cv[lang] = model\n",
    "    N_T_cv[lang] = sum(model.values())\n",
    "    \n",
    "    # Afegim els trigrammes al vocabulari global per a la B constant\n",
    "    for trigramma in model.keys():\n",
    "        vocabulari_global_cv.add(trigramma)\n",
    "\n",
    "# Estimació de la B constant i global\n",
    "B_global = len(vocabulari_global_cv)\n",
    "print(f\"Mida del vocabulari global estimat (B): {B_global} trigrammes.\")\n",
    "\n",
    "# 2. Funció per calcular probabilitat\n",
    "def log_probabilitat_frase(frase, model_lang, N_lang, B_glob, lmbda):\n",
    "    finder = TrigramCollocationFinder.from_words(\"  \" + frase + \"  \")\n",
    "    trigs_frase = finder.ngram_fd\n",
    "    \n",
    "    log_p = 0.0\n",
    "    for trig, freq in trigs_frase.items():\n",
    "        count_train = model_lang.get(trig, 0)\n",
    "        # Fórmula Lidstone n-gram probabilitat\n",
    "        p_lidstone = (count_train + lmbda) / (N_lang + lmbda * B_glob)\n",
    "        log_p += freq * math.log(p_lidstone)\n",
    "        \n",
    "    return log_p\n",
    "\n",
    "# 3. Optimització de Lambda via Cross-Validation\n",
    "valors_lambda = [0.001, 0.01, 0.1, 0.2, 0.5, 1.0]\n",
    "millor_lambda = None\n",
    "millor_accuracy = 0.0\n",
    "\n",
    "print(\"\\nIniciant Cross-Validation per trobar el millor lambda...\")\n",
    "\n",
    "for lmbda in valors_lambda:\n",
    "    encerts = 0\n",
    "    total_frases = 0\n",
    "    \n",
    "    for lang_real, llista_frases_val in dades_val.items():\n",
    "        for frase in llista_frases_val:\n",
    "            total_frases += 1\n",
    "            \n",
    "            # Busquem quin idioma dona la probabilitat més alta\n",
    "            max_prob = -float('inf')\n",
    "            idioma_predit = None\n",
    "            \n",
    "            for lang_model in idiomes:\n",
    "                prob = log_probabilitat_frase(\n",
    "                    frase, \n",
    "                    models_cv[lang_model], \n",
    "                    N_T_cv[lang_model], \n",
    "                    B_global, \n",
    "                    lmbda\n",
    "                )\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    idioma_predit = lang_model\n",
    "            \n",
    "            if idioma_predit == lang_real:\n",
    "                encerts += 1\n",
    "                \n",
    "    accuracy = encerts / total_frases\n",
    "    print(f\"Lambda: {lmbda} -> Accuracy Validació: {accuracy:.4f} ({encerts}/{total_frases})\")\n",
    "    \n",
    "    if accuracy > millor_accuracy:\n",
    "        millor_accuracy = accuracy\n",
    "        millor_lambda = lmbda\n",
    "\n",
    "print(f\"\\nEL MILLOR LAMBDA ÉS: {millor_lambda} amb un accuracy de {millor_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08e8126",
   "metadata": {},
   "source": [
    "## 4. Pas 3: Suavitzat de Lidstone i Càlcul de Probabilitats\n",
    "\n",
    "Per calcular la probabilitat que un text pertanyi a un idioma determinat, utilitzem el model de probabilitat d'n-grames assumint independència condicional (enfocament *Naive Bayes*). Com que el mètode de Màxima Versemblança (MLE) falla en assignar probabilitat zero als trigrammes no observats durant l'entrenament, utilitzem la **Llei de Lidstone**.\n",
    "\n",
    "La probabilitat suavitzada d'un trigramma s'estima com:\n",
    "\n",
    "$$P_{LID}(trig | lang) = \\frac{c(trig) + \\lambda}{N_{lang} + \\lambda \\cdot B}$$\n",
    "\n",
    "### 4.1. Definició i Justificació dels Paràmetres\n",
    "\n",
    "Per garantir que les probabilitats de diferents idiomes siguin justament comparables quan fem l'`argmax`, hem de definir acuradament els elements de la fórmula:\n",
    "\n",
    "* **$N_{lang}$ (Suma de freqüències):** És el nombre total d'aparicions de tots els trigrammes que formen el model d'aquell idioma (després d'aplicar el filtre). Aquest valor és **diferent per a cada idioma**, ja que depèn de la morfologia i la llargada exacta del corpus d'entrenament.\n",
    "* **$B$ (Espai mostral / Vocabulari possible):** Representa el nombre de trigrammes potencialment observables. Si cada idioma tingués la seva pròpia $B$, les probabilitats estarien distribuïdes sobre espais de diferent mida i no es podrien comparar directament. Per això, $B$ és una **constant global** igual per a tots els idiomes, calculada com la unió de tots els trigrammes únics trobats als corpus d'entrenament de totes les llengües.\n",
    "* **$\\lambda$ (Factor de suavitzat):** Determina quanta probabilitat es reserva per als trigrammes desconeguts. Ha de ser un **valor únic i global** per a tots els models. Si utilitzéssim un $\\lambda$ diferent per idioma, estaríem penalitzant de manera asimètrica la troballa de caràcters nous, trencant la justícia del classificador.\n",
    "\n",
    "### 4.2. Optimització de $\\lambda$ amb Validació Creuada (Cross-Validation)\n",
    "\n",
    "Atès que $\\lambda$ no és un valor aleatori, l'optimitzarem empíricament:\n",
    "1. Dividirem el corpus d'entrenament mitjançant *Hold-out Validation* (80% per entrenar, 20% per validar).\n",
    "2. Entrenarem els 6 models amb el 80% de les dades.\n",
    "3. Avaluarem el rendiment (Accuracy) sobre el 20% restant provant una bateria de possibles valors per a $\\lambda$ (des de valors molt petits fins a 1.0).\n",
    "4. Seleccionarem el $\\lambda$ que maximitzi l'exactitud per utilitzar-lo en la prova final (Test Set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df222727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "\n",
    "def obtenir_frases_netes(fitxer):\n",
    "    with open(fitxer, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return [frase for frase in text.split(\"  \") if len(frase.strip()) > 0]\n",
    "\n",
    "# 1. Separació Train/Validació (80/20) i creació de models\n",
    "idiomes = ['deu', 'eng', 'fra', 'ita', 'nld', 'spa']\n",
    "dades_train = {}\n",
    "dades_val = {}\n",
    "models_cv = {} \n",
    "N_T_cv = {}    \n",
    "\n",
    "vocabulari_global_cv = set() # Per estimar la B global\n",
    "\n",
    "for lang in idiomes:\n",
    "    fitxer = f\"{lang}_trn_clean.txt\"\n",
    "    frases = obtenir_frases_netes(fitxer)\n",
    "    \n",
    "    # Punt de tall: 80% entrenament, 20% validació\n",
    "    tall = int(len(frases) * 0.8)\n",
    "    dades_train[lang] = \"  \" + \"  \".join(frases[:tall]) + \"  \"\n",
    "    dades_val[lang] = frases[tall:] \n",
    "    \n",
    "    # Creem el model NLTK per al 80%\n",
    "    finder = TrigramCollocationFinder.from_words(dades_train[lang])\n",
    "    finder.apply_freq_filter(5)\n",
    "    model = finder.ngram_fd\n",
    "    \n",
    "    models_cv[lang] = model\n",
    "    N_T_cv[lang] = sum(model.values())\n",
    "    \n",
    "    for trigramma in model.keys():\n",
    "        vocabulari_global_cv.add(trigramma)\n",
    "\n",
    "B_global = len(vocabulari_global_cv)\n",
    "print(f\"Mida del vocabulari global estimat (B): {B_global} trigrammes únics.\\n\")\n",
    "\n",
    "def log_probabilitat_frase(frase, model_lang, N_lang, B_glob, lmbda):\n",
    "    finder = TrigramCollocationFinder.from_words(\"  \" + frase + \"  \")\n",
    "    trigs_frase = finder.ngram_fd\n",
    "    \n",
    "    log_p = 0.0\n",
    "    for trig, freq in trigs_frase.items():\n",
    "        count_train = model_lang.get(trig, 0)\n",
    "        p_lidstone = (count_train + lmbda) / (N_lang + lmbda * B_glob)\n",
    "        log_p += freq * math.log(p_lidstone)\n",
    "        \n",
    "    return log_p\n",
    "\n",
    "# 3. Optimització de Lambda amb un ventall més ampli\n",
    "# Hem afegit valors intermedis per trobar un òptim més ajustat\n",
    "valors_lambda = [0.001, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "millor_lambda = None\n",
    "millor_accuracy = 0.0\n",
    "\n",
    "print(\"Iniciant Validació Creuada (80/20)...\")\n",
    "\n",
    "for lmbda in valors_lambda:\n",
    "    encerts = 0\n",
    "    total_frases = 0\n",
    "    \n",
    "    for lang_real, llista_frases_val in dades_val.items():\n",
    "        for frase in llista_frases_val:\n",
    "            total_frases += 1\n",
    "            \n",
    "            max_prob = -float('inf')\n",
    "            idioma_predit = None\n",
    "            \n",
    "            for lang_model in idiomes:\n",
    "                prob = log_probabilitat_frase(\n",
    "                    frase, \n",
    "                    models_cv[lang_model], \n",
    "                    N_T_cv[lang_model], \n",
    "                    B_global, \n",
    "                    lmbda\n",
    "                )\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    idioma_predit = lang_model\n",
    "            \n",
    "            if idioma_predit == lang_real:\n",
    "                encerts += 1\n",
    "                \n",
    "    accuracy = encerts / total_frases\n",
    "    print(f\"Lambda: {lmbda:5.3f} -> Accuracy Validació: {accuracy:.4f} ({encerts}/{total_frases})\")\n",
    "    \n",
    "    if accuracy > millor_accuracy:\n",
    "        millor_accuracy = accuracy\n",
    "        millor_lambda = lmbda\n",
    "\n",
    "print(f\"\\nEL MILLOR LAMBDA ÉS: {millor_lambda} amb un accuracy de {millor_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd511114",
   "metadata": {},
   "source": [
    "## 4. Pas 3: Suavitzat de Lidstone i Càlcul de Probabilitats\n",
    "\n",
    "El mètode de Màxima Versemblança (MLE) falla perquè assigna una probabilitat de zero als trigrammes no observats durant l'entrenament, la qual cosa anul·la la probabilitat de tota la frase. Per evitar-ho, utilitzem una tècnica de suavitzat, concretament la **Llei de Lidstone**.\n",
    "\n",
    "[cite_start]La fórmula per estimar la probabilitat d'un trigramma $e_j$ en un corpus d'entrenament $T$ és:\n",
    "\n",
    "$$P^T(e_j) \\approx P_{LID}^T(e_j) = \\frac{c_T(e_j) + \\lambda}{N_T + \\lambda B}$$\n",
    "\n",
    "On:\n",
    "* **$c_T(e_j)$**: Freqüència del trigramma en el model d'entrenament (després del filtre de freq. $\\ge 5$).\n",
    "* **$N_T$**: Suma total de les freqüències de tots els trigrammes del model d'entrenament d'aquell idioma (després del filtre).\n",
    "* **$\\lambda$**: Paràmetre de suavitzat constant que trobarem mitjançant validació creuada.\n",
    "* **$B$**: L'espai mostral estimat (vocabulari). Tal com indica la teoria, per fer una bona estimació de totes les combinacions observables, $B$ es calcula sumant **tots els trigrammes únics observats abans d'aplicar el filtre**. $B$ és un valor global igual per a tots els models per garantir que les probabilitats siguin matemàticament comparables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e52d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "\n",
    "def obtenir_frases_netes(fitxer):\n",
    "    with open(fitxer, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return [frase for frase in text.split(\"  \") if len(frase.strip()) > 0]\n",
    "\n",
    "# 1. Separació Train/Validació (80/20) i creació de models\n",
    "idiomes = ['deu', 'eng', 'fra', 'ita', 'nld', 'spa']\n",
    "dades_train = {}\n",
    "dades_val = {}\n",
    "models_cv = {} \n",
    "N_T_cv = {}    \n",
    "\n",
    "vocabulari_global_cv = set() # Per estimar la B global amb TOT el vist\n",
    "\n",
    "for lang in idiomes:\n",
    "    fitxer = f\"{lang}_trn_clean.txt\"\n",
    "    frases = obtenir_frases_netes(fitxer)\n",
    "    \n",
    "    # Punt de tall: 80% entrenament, 20% validació\n",
    "    tall = int(len(frases) * 0.8)\n",
    "    dades_train[lang] = \"  \" + \"  \".join(frases[:tall]) + \"  \"\n",
    "    dades_val[lang] = frases[tall:] \n",
    "    \n",
    "    # Generem els trigrammes NLTK per al 80%\n",
    "    finder = TrigramCollocationFinder.from_words(dades_train[lang])\n",
    "    \n",
    "    # CANVI IMPORTANT: Afegim TOTS els trigrammes al vocabulari global ABANS de filtrar\n",
    "    for trigramma in finder.ngram_fd.keys():\n",
    "        vocabulari_global_cv.add(trigramma)\n",
    "        \n",
    "    # Ara sí, apliquem el filtre de classe (freqüència >= 5) pel model\n",
    "    finder.apply_freq_filter(5)\n",
    "    model = finder.ngram_fd\n",
    "    \n",
    "    # Guardem el model net i la N_T per aquest idioma\n",
    "    models_cv[lang] = model\n",
    "    N_T_cv[lang] = sum(model.values())\n",
    "\n",
    "# Calculem la B real i global\n",
    "B_global = len(vocabulari_global_cv)\n",
    "print(f\"Mida del vocabulari global estimat (B) ABANS de filtrar: {B_global} trigrammes únics.\\n\")\n",
    "\n",
    "def log_probabilitat_frase(frase, model_lang, N_lang, B_glob, lmbda):\n",
    "    finder = TrigramCollocationFinder.from_words(\"  \" + frase + \"  \")\n",
    "    trigs_frase = finder.ngram_fd\n",
    "    \n",
    "    log_p = 0.0\n",
    "    for trig, freq in trigs_frase.items():\n",
    "        count_train = model_lang.get(trig, 0)\n",
    "        p_lidstone = (count_train + lmbda) / (N_lang + lmbda * B_glob)\n",
    "        log_p += freq * math.log(p_lidstone)\n",
    "        \n",
    "    return log_p\n",
    "\n",
    "# 3. Optimització de Lambda \n",
    "valors_lambda = [0.001, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "millor_lambda = None\n",
    "millor_accuracy = 0.0\n",
    "\n",
    "print(\"Iniciant Validació Creuada (80/20)...\")\n",
    "\n",
    "for lmbda in valors_lambda:\n",
    "    encerts = 0\n",
    "    total_frases = 0\n",
    "    \n",
    "    for lang_real, llista_frases_val in dades_val.items():\n",
    "        for frase in llista_frases_val:\n",
    "            total_frases += 1\n",
    "            \n",
    "            max_prob = -float('inf')\n",
    "            idioma_predit = None\n",
    "            \n",
    "            for lang_model in idiomes:\n",
    "                prob = log_probabilitat_frase(\n",
    "                    frase, \n",
    "                    models_cv[lang_model], \n",
    "                    N_T_cv[lang_model], \n",
    "                    B_global, \n",
    "                    lmbda\n",
    "                )\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    idioma_predit = lang_model\n",
    "            \n",
    "            if idioma_predit == lang_real:\n",
    "                encerts += 1\n",
    "                \n",
    "    accuracy = encerts / total_frases\n",
    "    print(f\"Lambda: {lmbda:5.3f} -> Accuracy Validació: {accuracy:.4f} ({encerts}/{total_frases})\")\n",
    "    \n",
    "    if accuracy > millor_accuracy:\n",
    "        millor_accuracy = accuracy\n",
    "        millor_lambda = lmbda\n",
    "\n",
    "print(f\"\\nEL MILLOR LAMBDA ÉS: {millor_lambda} amb un accuracy de {millor_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd451f",
   "metadata": {},
   "source": [
    "fer mes smoothing\n",
    "- absolute discounting\n",
    "- interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59195366",
   "metadata": {},
   "source": [
    "### 4.3. Alternatives de Suavitzat: Descompte Absolut i Interpolació\n",
    "\n",
    "Per assegurar que estem utilitzant el millor model possible, no ens limitarem a la Llei de Lidstone. Provarem i optimitzarem dues tècniques addicionals.\n",
    "\n",
    "#### A) Descompte Absolut (Absolute Discounting)\n",
    "En comptes d'afegir massa de probabilitat a tots els n-grames, el Descompte Absolut **resta una quantitat constant $\\alpha$** (on $0 < \\alpha < 1$) a les freqüències dels trigrammes que sí que hem observat. \n",
    "\n",
    "La massa de probabilitat total \"robada\" als trigrammes coneguts és $\\alpha \\cdot V_T$ (on $V_T$ és el nombre de trigrammes únics observats en l'entrenament d'aquell idioma). Aquesta massa es reparteix uniformement, però **només entre els trigrammes que no hem vist mai**. Com que el vocabulari total és $B$, el nombre de trigrammes no vistos és exactament $B - V_T$.\n",
    "\n",
    "Això ens deixa una funció definida a trossos:\n",
    "\n",
    "* **Si el trigramma s'ha vist ($c_T(e_j) > 0$):**\n",
    "  $$P_{AD}(e_j) = \\frac{c_T(e_j) - \\alpha}{N_T}$$\n",
    "\n",
    "* **Si el trigramma NO s'ha vist ($c_T(e_j) = 0$):**\n",
    "  $$P_{AD}(e_j) = \\frac{\\frac{V_T \\cdot \\alpha}{B - V_T}}{N_T}$$\n",
    "\n",
    "#### B) Interpolació Lineal (Linear Interpolation)\n",
    "La interpolació consisteix a construir un model més robust combinant (interpolant) la probabilitat del trigrama amb les probabilitats d'ordre inferior (bigrames i unigrames) del mateix idioma. D'aquesta manera, si un trigrama no s'ha vist mai, el model es pot recolzar en contextos més curts en lloc d'anul·lar la probabilitat.\n",
    "\n",
    "Donat un trigrama $e_j = (w_{i-2}, w_{i-1}, w_i)$, la fórmula utilitzada és:\n",
    "\n",
    "$$P_{INT}(d) \\approx \\lambda_0 \\cdot P(w_i, w_{i-1}, w_{i-2}) + \\lambda_1 \\cdot P(w_i, w_{i-1}) + \\lambda_2 \\cdot P(w_i)$$\n",
    "\n",
    "Amb la condició estricta que:\n",
    "$$\\lambda_0 + \\lambda_1 + \\lambda_2 = 1$$\n",
    "\n",
    "On:\n",
    "* $P(w_i, w_{i-1}, w_{i-2})$ és la probabilitat MLE del trigrama.\n",
    "* $P(w_i, w_{i-1})$ és la probabilitat MLE del bigrama (els dos últims caràcters).\n",
    "* $P(w_i)$ és la probabilitat MLE de l'unigrama (l'últim caràcter).\n",
    "* Els paràmetres $\\lambda$ indiquen el \"pes\" o confiança que li donem a cada nivell (habitualment $\\lambda_0 > \\lambda_1 > \\lambda_2$).\n",
    "\n",
    "**Objectiu:** Executarem la validació creuada (80/20) provant diferents combinacions de $\\lambda$ per trobar la barreja òptima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24660707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparació completada. B Global (Trigrammes únics): 43798\n",
      "\n",
      "--- Avaluant tècnica: LIDSTONE ---\n",
      "  Param=0.01            -> Accuracy: 0.9981\n",
      "  Param=0.1             -> Accuracy: 0.9982\n",
      "  Param=0.25            -> Accuracy: 0.9984\n",
      "  Param=0.5             -> Accuracy: 0.9984\n",
      "  Param=0.75            -> Accuracy: 0.9985\n",
      "  Param=1.0             -> Accuracy: 0.9984\n",
      "  >> Guanyador lidstone: Param=0.75 (Acc=0.9985)\n",
      "\n",
      "--- Avaluant tècnica: ABSOLUTE_DISCOUNTING ---\n",
      "  Param=0.1             -> Accuracy: 0.9981\n",
      "  Param=0.5             -> Accuracy: 0.9982\n",
      "  Param=0.75            -> Accuracy: 0.9982\n",
      "  Param=0.9             -> Accuracy: 0.9983\n",
      "  >> Guanyador absolute_discounting: Param=0.9 (Acc=0.9983)\n",
      "\n",
      "--- Avaluant tècnica: INTERPOLATION ---\n",
      "  Param=(0.6, 0.3, 0.1) -> Accuracy: 0.9881\n",
      "  Param=(0.7, 0.2, 0.1) -> Accuracy: 0.9885\n",
      "  Param=(0.8, 0.15, 0.05) -> Accuracy: 0.9932\n",
      "  Param=(0.5, 0.4, 0.1) -> Accuracy: 0.9880\n",
      "  >> Guanyador interpolation: Param=(0.8, 0.15, 0.05) (Acc=0.9932)\n",
      "\n",
      "=== RESUM FINAL DE VALIDACIÓ ===\n",
      "\n",
      "LA MILLOR TÈCNICA ÉS: LIDSTONE amb un accuracy de 0.9985\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import nltk\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "\n",
    "def obtenir_frases_netes(fitxer):\n",
    "    with open(fitxer, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return [frase for frase in text.split(\"  \") if len(frase.strip()) > 0]\n",
    "\n",
    "# --- 1. SEPARACIÓ I PREPARACIÓ ---\n",
    "idiomes = ['deu', 'eng', 'fra', 'ita', 'nld', 'spa']\n",
    "\n",
    "# Guardarem models d'unigrames (1), bigrames (2) i trigrames (3)\n",
    "models_1_cv, models_2_cv, models_3_cv = {}, {}, {}\n",
    "N_1_cv, N_2_cv, N_3_cv = {}, {}, {}\n",
    "V_T_cv = {}\n",
    "dades_train, dades_val = {}, {}\n",
    "\n",
    "vocabulari_global_cv = set()\n",
    "\n",
    "for lang in idiomes:\n",
    "    frases = obtenir_frases_netes(f\"{lang}_trn_clean.txt\")\n",
    "    tall = int(len(frases) * 0.8)\n",
    "    text_train = \"  \" + \"  \".join(frases[:tall]) + \"  \"\n",
    "    \n",
    "    dades_train[lang] = text_train\n",
    "    dades_val[lang] = frases[tall:]\n",
    "    \n",
    "    # Text com a llista de caràcters per processar fàcilment\n",
    "    llista_chars = list(text_train)\n",
    "    \n",
    "    # Models de Suport (Unigrames i Bigrames)\n",
    "    models_1_cv[lang] = nltk.FreqDist(llista_chars)\n",
    "    models_2_cv[lang] = nltk.FreqDist(nltk.ngrams(llista_chars, 2))\n",
    "    N_1_cv[lang] = len(llista_chars)\n",
    "    N_2_cv[lang] = len(llista_chars) - 1\n",
    "    \n",
    "    # Model Principal (Trigrames)\n",
    "    finder = TrigramCollocationFinder.from_words(text_train)\n",
    "    \n",
    "    # B constant: tots els trigrammes abans de filtrar\n",
    "    for trigramma in finder.ngram_fd.keys():\n",
    "        vocabulari_global_cv.add(trigramma)\n",
    "        \n",
    "    finder.apply_freq_filter(5)\n",
    "    model3 = finder.ngram_fd\n",
    "    \n",
    "    models_3_cv[lang] = model3\n",
    "    N_3_cv[lang] = sum(model3.values())\n",
    "    V_T_cv[lang] = len(model3) # Trigrammes únics (necessari per AD)\n",
    "\n",
    "B_global = len(vocabulari_global_cv)\n",
    "print(f\"Preparació completada. B Global (Trigrammes únics): {B_global}\\n\")\n",
    "\n",
    "# --- 2. FUNCIONS DE PROBABILITAT PER A CADA TÈCNICA ---\n",
    "\n",
    "def probabilitat_frase(frase, lang, parametre, tecnica):\n",
    "    finder = TrigramCollocationFinder.from_words(\"  \" + frase + \"  \")\n",
    "    trigs_frase = finder.ngram_fd\n",
    "    \n",
    "    # Variables del trigrama\n",
    "    model3 = models_3_cv[lang]\n",
    "    N3 = N_3_cv[lang] \n",
    "    V = V_T_cv[lang] \n",
    "    \n",
    "    log_p = 0.0\n",
    "    \n",
    "    for trig, freq in trigs_frase.items():\n",
    "        c3 = model3.get(trig, 0)\n",
    "        \n",
    "        if tecnica == 'lidstone':\n",
    "            p = (c3 + parametre) / (N3 + parametre * B_global)\n",
    "            \n",
    "        elif tecnica == 'absolute_discounting':\n",
    "            alpha = parametre\n",
    "            if c3 == 0:\n",
    "                p = (V * alpha / (B_global - V)) / N3\n",
    "            else:\n",
    "                p = (c3 - alpha) / N3\n",
    "                \n",
    "        elif tecnica == 'interpolation':\n",
    "            l0, l1, l2 = parametre # Desempaquetem la tupla (lambda0, lambda1, lambda2)\n",
    "            c1, c2, c3_char = trig # (w_{i-2}, w_{i-1}, w_i)\n",
    "            \n",
    "            # MLE Trigrama\n",
    "            p3 = c3 / N3 if N3 > 0 else 0\n",
    "            # MLE Bigrama (w_{i-1}, w_i)\n",
    "            p2 = models_2_cv[lang].get((c2, c3_char), 0) / N_2_cv[lang]\n",
    "            # MLE Unigrama (w_i)\n",
    "            p1 = models_1_cv[lang].get(c3_char, 0) / N_1_cv[lang]\n",
    "            \n",
    "            # Fórmula de la imatge\n",
    "            p = l0 * p3 + l1 * p2 + l2 * p1\n",
    "            \n",
    "            # Evitem el log(0) extrem si el caràcter no existeix en absolut\n",
    "            if p <= 0:\n",
    "                p = 1e-10 \n",
    "            \n",
    "        log_p += freq * math.log(p)\n",
    "        \n",
    "    return log_p\n",
    "\n",
    "# --- 3. BUCLE D'AVALUACIÓ PER A LES 3 TÈCNIQUES ---\n",
    "\n",
    "# Per a la interpolació provem tuples (l0, l1, l2) que sumin 1\n",
    "proves = {\n",
    "    'lidstone': [0.01, 0.1, 0.25, 0.5, 0.75, 1.0],\n",
    "    'absolute_discounting': [0.1, 0.5, 0.75, 0.9],\n",
    "    'interpolation': [\n",
    "        (0.6, 0.3, 0.1), \n",
    "        (0.7, 0.2, 0.1), \n",
    "        (0.8, 0.15, 0.05), \n",
    "        (0.5, 0.4, 0.1)\n",
    "    ]\n",
    "}\n",
    "\n",
    "resultats_cv = {}\n",
    "\n",
    "for tecnica, parametres in proves.items():\n",
    "    print(f\"--- Avaluant tècnica: {tecnica.upper()} ---\")\n",
    "    millor_acc_tecnica = 0.0\n",
    "    millor_param_tecnica = None\n",
    "    \n",
    "    for param in parametres:\n",
    "        encerts = 0\n",
    "        total_frases = 0\n",
    "        \n",
    "        for lang_real, llista_frases in dades_val.items():\n",
    "            for frase in llista_frases:\n",
    "                total_frases += 1\n",
    "                max_prob = -float('inf')\n",
    "                idioma_predit = None\n",
    "                \n",
    "                for lang_model in idiomes:\n",
    "                    prob = probabilitat_frase(frase, lang_model, param, tecnica)\n",
    "                    if prob > max_prob:\n",
    "                        max_prob = prob\n",
    "                        idioma_predit = lang_model\n",
    "                \n",
    "                if idioma_predit == lang_real:\n",
    "                    encerts += 1\n",
    "                    \n",
    "        accuracy = encerts / total_frases\n",
    "        print(f\"  Param={str(param):<15} -> Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        if accuracy > millor_acc_tecnica:\n",
    "            millor_acc_tecnica = accuracy\n",
    "            millor_param_tecnica = param\n",
    "            \n",
    "    resultats_cv[tecnica] = {'param': millor_param_tecnica, 'acc': millor_acc_tecnica}\n",
    "    print(f\"  >> Guanyador {tecnica}: Param={millor_param_tecnica} (Acc={millor_acc_tecnica:.4f})\\n\")\n",
    "\n",
    "# --- 4. RESULTAT FINAL ---\n",
    "print(\"=== RESUM FINAL DE VALIDACIÓ ===\")\n",
    "millor_tecnica_global = None\n",
    "millor_acc_global = 0.0\n",
    "\n",
    "for tec, res in resultats_cv.items():\n",
    "    if res['acc'] > millor_acc_global:\n",
    "        millor_acc_global = res['acc']\n",
    "        millor_tecnica_global = tec\n",
    "\n",
    "print(f\"\\nLA MILLOR TÈCNICA ÉS: {millor_tecnica_global.upper()} amb un accuracy de {millor_acc_global:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef25763",
   "metadata": {},
   "source": [
    "## 5. Pas 4: Avaluació Final i Matriu de Confusió\n",
    "\n",
    "Després d'executar la validació creuada sobre el conjunt d'entrenament, hem determinat que la millor tècnica de suavitzat per a les nostres dades és la **Llei de Lidstone amb un paràmetre $\\lambda = 0.75$**, assolint una precisió superior al 99.8%.\n",
    "\n",
    "En aquesta fase final, procedim a avaluar el rendiment real del classificador sobre dades mai vistes.\n",
    "\n",
    "### 5.1. Entrenament del Model Definitiu\n",
    "Per aprofitar tot el coneixement disponible, construïm els models de llenguatge definitius utilitzant el **100% del corpus d'entrenament** (`_trn_clean.txt`) per a cada idioma, aplicant el filtre de freqüència $\\ge 5$ i calculant la constant global $B$ amb tots els trigrammes previs al filtratge.\n",
    "\n",
    "### 5.2. Avaluació sobre el Test Set\n",
    "El conjunt de prova consta de 10.000 frases per idioma (`_tst_clean.txt`). Cada frase serà avaluada pels 6 models d'idioma, i se li assignarà l'idioma que maximitzi la probabilitat (utilitzant la fórmula de Lidstone optimitzada).\n",
    "\n",
    "### 5.3. Matriu de Confusió\n",
    "Per entendre millor els errors del model, generarem una **Matriu de Confusió**. Aquesta taula ens permetrà analitzar les classificacions incorrectes i veure si hi ha confusió sistemàtica entre llengües morfològicament properes (com el francès, l'espanyol i l'italià, o l'anglès, l'alemany i el neerlandès)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f27b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b845608",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install seaborn \n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "586dbe15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:90: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:90: SyntaxWarning: invalid escape sequence '\\l'\n",
      "C:\\Users\\berta\\AppData\\Local\\Temp\\ipykernel_25060\\906424548.py:90: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  plt.title(f'Matriu de Confusió (Lidstone $\\lambda=0.75$) - Acc: {acc_final:.4f}')\n",
      "C:\\Users\\berta\\AppData\\Local\\Temp\\ipykernel_25060\\906424548.py:90: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  plt.title(f'Matriu de Confusió (Lidstone $\\lambda=0.75$) - Acc: {acc_final:.4f}')\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmath\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcollocations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrigramCollocationFinder\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, confusion_matrix\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def obtenir_frases_netes(fitxer):\n",
    "    with open(fitxer, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return [frase for frase in text.split(\"  \") if len(frase.strip()) > 0]\n",
    "\n",
    "idiomes = ['deu', 'eng', 'fra', 'ita', 'nld', 'spa']\n",
    "\n",
    "print(\"1. Construint els models definitius (100% Train)...\")\n",
    "models_definitius, N_T_def = {}, {}\n",
    "vocabulari_global_def = set()\n",
    "\n",
    "for lang in idiomes:\n",
    "    fitxer_train = f\"{lang}_trn_clean.txt\"\n",
    "    with open(fitxer_train, 'r', encoding='utf-8') as f:\n",
    "        text_complet = f.read()\n",
    "    \n",
    "    finder = TrigramCollocationFinder.from_words(text_complet)\n",
    "    \n",
    "    # B constant: tots els trigrammes abans de filtrar\n",
    "    for trigramma in finder.ngram_fd.keys():\n",
    "        vocabulari_global_def.add(trigramma)\n",
    "        \n",
    "    # Apliquem filtre\n",
    "    finder.apply_freq_filter(5)\n",
    "    model = finder.ngram_fd\n",
    "    \n",
    "    models_definitius[lang] = model\n",
    "    N_T_def[lang] = sum(model.values())\n",
    "\n",
    "B_global_def = len(vocabulari_global_def)\n",
    "print(f\"   -> B Global Definitiva: {B_global_def} trigrammes únics.\")\n",
    "\n",
    "# Funció de Lidstone (Guanyadora)\n",
    "def probabilitat_lidstone(frase, lang, lmbda=0.75):\n",
    "    finder = TrigramCollocationFinder.from_words(\"  \" + frase + \"  \")\n",
    "    trigs_frase = finder.ngram_fd\n",
    "    \n",
    "    model = models_definitius[lang]\n",
    "    N = N_T_def[lang]\n",
    "    log_p = 0.0\n",
    "    \n",
    "    for trig, freq in trigs_frase.items():\n",
    "        c = model.get(trig, 0)\n",
    "        p = (c + lmbda) / (N + lmbda * B_global_def)\n",
    "        log_p += freq * math.log(p)\n",
    "        \n",
    "    return log_p\n",
    "\n",
    "print(\"\\n2. Avaluant sobre el conjunt de Test...\")\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for lang_real in idiomes:\n",
    "    fitxer_test = f\"{lang_real}_tst_clean.txt\"\n",
    "    frases_test = obtenir_frases_netes(fitxer_test)\n",
    "    \n",
    "    for frase in frases_test:\n",
    "        y_true.append(lang_real)\n",
    "        \n",
    "        max_prob = -float('inf')\n",
    "        idioma_predit = None\n",
    "        \n",
    "        for lang_model in idiomes:\n",
    "            prob = probabilitat_lidstone(frase, lang_model, lmbda=0.75)\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                idioma_predit = lang_model\n",
    "                \n",
    "        y_pred.append(idioma_predit)\n",
    "\n",
    "# --- RESULTATS I MATRIU ---\n",
    "acc_final = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\n=== RESULTAT FINAL ===\")\n",
    "print(f\"Accuracy en Test: {acc_final:.4f} ({int(acc_final * len(y_true))}/{len(y_true)} encerts)\")\n",
    "\n",
    "# Generació de la Matriu de Confusió\n",
    "cm = confusion_matrix(y_true, y_pred, labels=idiomes)\n",
    "df_cm = pd.DataFrame(cm, index=idiomes, columns=idiomes)\n",
    "\n",
    "# Mostrar la matriu de forma visual\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title(f'Matriu de Confusió (Lidstone $\\lambda=0.75$) - Acc: {acc_final:.4f}')\n",
    "plt.ylabel('Idioma Real')\n",
    "plt.xlabel('Idioma Predit')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMatriu de Confusió (Text):\")\n",
    "print(df_cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_PLH (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
