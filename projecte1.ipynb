{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "168cc0fb",
   "metadata": {},
   "source": [
    "# Pràctica 1: Identificació d'Idioma\n",
    "**Assignatura:** Processament del Llenguatge Humà (PLH)  \n",
    "**Model:** Model de llenguatge basat en n-grames de caràcters \n",
    "\n",
    "## 1. Introducció\n",
    "L'objectiu d'aquesta pràctica és construir un classificador automàtic capaç d'assignar un idioma $l_i$ a un document $d$ d'entre un conjunt de 6 llengües europees: alemany (deu), anglès (eng), francès (fra), italià (ita), neerlandès (nld) i castellà (spa).\n",
    "\n",
    "El sistema es basa en la hipòtesi que les freqüències de certes seqüències de lletres (n-grames) són úniques per a cada idioma. En aquest cas, utilitzarem **trigrammes de caràcters** (n=3).\n",
    "\n",
    "### Recursos\n",
    "**Entrenament (Training):** 30.000 frases per idioma del corpus Wortschatz Leipzig.\n",
    "\n",
    "**Validació (Test):** 10.000 frases per idioma per avaluar la precisió (accuracy) i generar la matriu de confusió.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Pas 1: Preprocessament del Text\n",
    "El text brut ha de ser normalitzat abans de l'entrenament per evitar biaixos causats per elements no lingüístics. \n",
    "\n",
    "### Procediment de neteja:\n",
    "1. **Eliminar els dígits**: S'eliminen els números del text, ja que no són informatius per identificar l'idioma.\n",
    "2. **Convertir a minúscula**: Es normalitzen tots els caràcters per reduir la dispersió de dades.\n",
    "3. **Substitució d'espais**: Es canvien els espais en blanc continus (o tabulacions) per un sol espai.\n",
    "4. **Unió de frases**: Es concatenen totes les frases del corpus inserint un **espai doble** entre elles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b1d5dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processant deu_trn.txt...\n",
      "Desat: deu_trn_clean.txt\n",
      "Processant deu_tst.txt...\n",
      "Desat: deu_tst_clean.txt\n",
      "Processant eng_trn.txt...\n",
      "Desat: eng_trn_clean.txt\n",
      "Processant eng_tst.txt...\n",
      "Desat: eng_tst_clean.txt\n",
      "Processant fra_trn.txt...\n",
      "Desat: fra_trn_clean.txt\n",
      "Processant fra_tst.txt...\n",
      "Desat: fra_tst_clean.txt\n",
      "Processant ita_trn.txt...\n",
      "Desat: ita_trn_clean.txt\n",
      "Processant ita_tst.txt...\n",
      "Desat: ita_tst_clean.txt\n",
      "Processant nld_trn.txt...\n",
      "Desat: nld_trn_clean.txt\n",
      "Processant nld_tst.txt...\n",
      "Desat: nld_tst_clean.txt\n",
      "Processant spa_trn.txt...\n",
      "Desat: spa_trn_clean.txt\n",
      "Processant spa_tst.txt...\n",
      "Desat: spa_tst_clean.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def preprocess_text(frases):\n",
    "    \"\"\"\n",
    "    Neteja del text:\n",
    "    - Elimina dígits.\n",
    "    - Minúscules.\n",
    "    - Normalitza espais.\n",
    "    - Concatena amb espai doble al mig, i també a l'inici i al final.\n",
    "    \"\"\"\n",
    "    neteja = []\n",
    "\n",
    "    for linia in frases:\n",
    "        # 1. Eliminar els dígits\n",
    "        text = re.sub(r'\\d+', '', linia)\n",
    "        # 2. Convertir a minúscules \n",
    "        text = text.lower()\n",
    "        # 3. Substituir espais blancs continus per un de sol\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        if text:\n",
    "            neteja.append(text)\n",
    "    \n",
    "    # 4. Concatena les frases amb un espai doble al mig, a l'inici i al final\n",
    "    return \"  \" + \"  \".join(neteja) + \"  \"\n",
    "\n",
    "# Llista d'idiomes\n",
    "idiomes = ['deu', 'eng', 'fra', 'ita', 'nld', 'spa'] \n",
    "\n",
    "for lang in idiomes:\n",
    "    for tipus in ['trn', 'tst']:\n",
    "        nom_fitxer = f\"{lang}_{tipus}.txt\"\n",
    "        \n",
    "        if os.path.exists(nom_fitxer):\n",
    "            print(f\"Processant {nom_fitxer}...\")\n",
    "            with open(nom_fitxer, 'r', encoding='utf-8') as f:\n",
    "                linies = f.readlines()\n",
    "            \n",
    "            text_net = preprocess_text(linies)\n",
    "            \n",
    "            # Guardem el resultat en un fitxer nou\n",
    "            nom_sortida = f\"{lang}_{tipus}_clean.txt\"\n",
    "            with open(nom_sortida, 'w', encoding='utf-8') as f_out:\n",
    "                f_out.write(text_net)\n",
    "            print(f\"Desat: {nom_sortida}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3948ccd9",
   "metadata": {},
   "source": [
    "## 3. Pas 2: Generació del Model i Filtratge amb NLTK\n",
    "\n",
    "Per a la construcció del model de llenguatge basat en caràcters, utilitzarem la llibreria **NLTK**, concretament la classe `TrigramCollocationFinder`.\n",
    "\n",
    "### Procediment:\n",
    "1. **Extracció de Trigrammes de caràcters:** Com que volem un model basat en caràcters, passarem l'string sencer (el text prèviament netejat) a la funció `from_words()`. D'aquesta manera, NLTK tractarà cada lletra i espai com una unitat bàsica, generant seqüències de 3 caràcters (ex: `('c', 'a', 's')`).\n",
    "2. **Filtratge de freqüències:** Per reduir el soroll estadístic i eliminar combinacions rares o errors, eliminem els trigrammes que apareguin menys de 5 vegades al corpus. Utilitzarem la funció nativa d'NLTK `apply_freq_filter(5)`.\n",
    "3. **Obtenció del diccionari:** Finalment, extreurem les freqüències filtrades mitjançant l'atribut `ngram_fd`, que ens retorna un diccionari de freqüències (FreqDist) llest per ser utilitzat en el càlcul de probabilitats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a212d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciant la creació dels models de llenguatge...\n",
      "Model per 'deu' generat amb èxit. Trigrammes únics: 11321\n",
      "Model per 'eng' generat amb èxit. Trigrammes únics: 9390\n",
      "Model per 'fra' generat amb èxit. Trigrammes únics: 10421\n",
      "Model per 'ita' generat amb èxit. Trigrammes únics: 8325\n",
      "Model per 'nld' generat amb èxit. Trigrammes únics: 10148\n",
      "Model per 'spa' generat amb èxit. Trigrammes únics: 9294\n",
      "\n",
      "Tots els models d'entrenament han estat generats i emmagatzemats a 'models_entrenament'.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "\n",
    "# Diccionari global per emmagatzemar la freqüència dels trigrammes de cada idioma\n",
    "models_entrenament = {}\n",
    "\n",
    "idiomes = ['deu', 'eng', 'fra', 'ita', 'nld', 'spa']\n",
    "\n",
    "print(\"Iniciant la creació dels models de llenguatge...\")\n",
    "\n",
    "for lang in idiomes:\n",
    "    nom_fitxer_train = f\"{lang}_trn_clean.txt\"\n",
    "    \n",
    "    # Llegim el fitxer de text netejat d'entrenament\n",
    "    with open(nom_fitxer_train, 'r', encoding='utf-8') as f:\n",
    "        text_net = f.read()\n",
    "    \n",
    "    # 1. Generem els trigrammes de caràcters utilitzant NLTK\n",
    "    # NLTK genera tuples de 3 caràcters: ex. ('t', 'h', 'e')\n",
    "    finder = TrigramCollocationFinder.from_words(text_net)\n",
    "    \n",
    "    # 2. Apliquem el filtre per eliminar els trigrammes amb freqüència < 5\n",
    "    finder.apply_freq_filter(5)\n",
    "    \n",
    "    # 3. Guardem la distribució de freqüències (FreqDist) al nostre diccionari\n",
    "    models_entrenament[lang] = finder.ngram_fd\n",
    "    \n",
    "    # Imprimim informació per validar que s'ha creat correctament\n",
    "    num_trigrames = len(models_entrenament[lang])\n",
    "    print(f\"Model per '{lang}' generat amb èxit. Trigrammes únics: {num_trigrames}\")\n",
    "\n",
    "print(\"\\nTots els models d'entrenament han estat generats i emmagatzemats a 'models_entrenament'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce55711",
   "metadata": {},
   "source": [
    "## 4. Pas 3: Suavitzat de Lidstone per a N-grames\n",
    "\n",
    "Per calcular la probabilitat que un text pertanyi a un idioma determinat, utilitzem el model de probabilitat d'n-grames assumint independència condicional (enfocament *Naive Bayes*). La probabilitat del document sencer és el producte de les probabilitats individuals de cada trigramma que el compon.\n",
    "\n",
    "Com que el mètode de Màxima Versemblança (MLE) assigna probabilitat zero als trigrammes no observats durant l'entrenament, utilitzem la **Llei de Lidstone**.\n",
    "\n",
    "$$P_{LID}(trigramma | idioma) = \\frac{c(trigramma) + \\lambda}{N_{idioma} + \\lambda \\cdot B}$$\n",
    "\n",
    "### 4.1. L'espai mostral i el paràmetre $B$\n",
    "El paràmetre $B$ representa la mida del vocabulari, és a dir, el nombre de trigrammes *potencialment observables*. \n",
    "\n",
    "**Per què $B$ ha de ser igual per a tots els idiomes?**\n",
    "Si volem comparar de forma justa $P(text | anglès)$ i $P(text | francès)$, ambdós models han de basar-se en el **mateix espai mostral d'esdeveniments**. Si l'anglès tingués una $B$ de 2.000 i el francès una $B$ de 3.000, les probabilitats estarien distribuïdes sobre espais de diferent mida i no serien comparables.\n",
    "\n",
    "**Com estimem $B$?**\n",
    "Teòricament, $B$ podria ser totes les combinacions matemàtiques possibles de 3 caràcters (ex: si tenim un alfabet de 30 lletres i espais, $30^3 = 27.000$). No obstant això, moltes d'aquestes combinacions (com 'qqq' o 'zxw') no existeixen en cap idioma humà real. \n",
    "La millor estimació de l'espai mostral real és la **unió de tots els trigrammes únics trobats en els corpus d'entrenament de tots els idiomes junts**. Aquesta serà la nostra $B$ global i constant.\n",
    "\n",
    "### 4.2. Optimització de $\\lambda$ amb Cross-Validation (Validació Creuada)\n",
    "El paràmetre $\\lambda$ controla quant de \"pes\" traiem als trigrammes observats per repartir-lo entre els no observats. Assumir $\\lambda = 0.5$ (Regla de Jeffrey) o $\\lambda = 1$ (Regla de Laplace) sense proves no és òptim.\n",
    "\n",
    "Utilitzarem **Cross-Validation**:\n",
    "1. Dividirem el nostre corpus d'entrenament en dues parts: un sub-conjunt d'entrenament (ex: 80%) i un de validació (20%).\n",
    "2. Entrenarem el model només amb el 80%.\n",
    "3. Avaluarem l'exactitud (*accuracy*) en el 20% de validació utilitzant diferents valors de $\\lambda$ (ex: 0.01, 0.1, 0.2, 0.5, 1.0).\n",
    "4. Ens quedarem amb el $\\lambda$ que assoleixi el millor percentatge d'encerts per utilitzar-lo en el test final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaada39",
   "metadata": {},
   "source": [
    "te sentit fer mateixa b totes les llengues per aixi poder comparar, explicarlo bien lo de todas las combinaciones..., justificarlo bien ya que es una estimacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e41d3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mida del vocabulari global estimat (B): 20366 trigrammes.\n",
      "\n",
      "Iniciant Cross-Validation per trobar el millor lambda...\n",
      "Lambda: 0.001 -> Accuracy Validació: 0.9976 (35888/35973)\n",
      "Lambda: 0.01 -> Accuracy Validació: 0.9981 (35903/35973)\n",
      "Lambda: 0.1 -> Accuracy Validació: 0.9982 (35909/35973)\n",
      "Lambda: 0.2 -> Accuracy Validació: 0.9983 (35911/35973)\n",
      "Lambda: 0.5 -> Accuracy Validació: 0.9984 (35916/35973)\n",
      "Lambda: 1.0 -> Accuracy Validació: 0.9984 (35917/35973)\n",
      "\n",
      "EL MILLOR LAMBDA ÉS: 1.0 amb un accuracy de 0.9984\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "\n",
    "# Suposem que llegim el text net que vas guardar, separant per frases (amb el doble espai)\n",
    "def obtenir_frases_netes(fitxer):\n",
    "    with open(fitxer, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    # Separem pel doble espai que vam introduir al preprocés per recuperar les frases\n",
    "    # i eliminem elements buits\n",
    "    return [frase for frase in text.split(\"  \") if len(frase.strip()) > 0]\n",
    "\n",
    "# 1. Separació Train/Validació (80/20) i creació de models\n",
    "idiomes = ['deu', 'eng', 'fra', 'ita', 'nld', 'spa']\n",
    "dades_train = {}\n",
    "dades_val = {}\n",
    "models_cv = {} # Models entrenats només amb el 80%\n",
    "N_T_cv = {}    # Nombre total de trigrammes (freqüències) del 80%\n",
    "\n",
    "vocabulari_global_cv = set() # Per estimar la B\n",
    "\n",
    "for lang in idiomes:\n",
    "    fitxer = f\"{lang}_trn_clean.txt\"\n",
    "    frases = obtenir_frases_netes(fitxer)\n",
    "    \n",
    "    # Punt de tall: 80% entrenament, 20% validació\n",
    "    tall = int(len(frases) * 0.8)\n",
    "    dades_train[lang] = \"  \" + \"  \".join(frases[:tall]) + \"  \"\n",
    "    dades_val[lang] = frases[tall:] # Llista de frases per validar\n",
    "    \n",
    "    # Creem el model NLTK per al 80%\n",
    "    finder = TrigramCollocationFinder.from_words(dades_train[lang])\n",
    "    finder.apply_freq_filter(5) # Apliquem el filtre de classe\n",
    "    model = finder.ngram_fd\n",
    "    \n",
    "    models_cv[lang] = model\n",
    "    N_T_cv[lang] = sum(model.values())\n",
    "    \n",
    "    # Afegim els trigrammes al vocabulari global per a la B constant\n",
    "    for trigramma in model.keys():\n",
    "        vocabulari_global_cv.add(trigramma)\n",
    "\n",
    "# Estimació de la B constant i global\n",
    "B_global = len(vocabulari_global_cv)\n",
    "print(f\"Mida del vocabulari global estimat (B): {B_global} trigrammes.\")\n",
    "\n",
    "# 2. Funció per calcular probabilitat\n",
    "def log_probabilitat_frase(frase, model_lang, N_lang, B_glob, lmbda):\n",
    "    finder = TrigramCollocationFinder.from_words(\"  \" + frase + \"  \")\n",
    "    trigs_frase = finder.ngram_fd\n",
    "    \n",
    "    log_p = 0.0\n",
    "    for trig, freq in trigs_frase.items():\n",
    "        count_train = model_lang.get(trig, 0)\n",
    "        # Fórmula Lidstone n-gram probabilitat\n",
    "        p_lidstone = (count_train + lmbda) / (N_lang + lmbda * B_glob)\n",
    "        log_p += freq * math.log(p_lidstone)\n",
    "        \n",
    "    return log_p\n",
    "\n",
    "# 3. Optimització de Lambda via Cross-Validation\n",
    "valors_lambda = [0.001, 0.01, 0.1, 0.2, 0.5, 1.0]\n",
    "millor_lambda = None\n",
    "millor_accuracy = 0.0\n",
    "\n",
    "print(\"\\nIniciant Cross-Validation per trobar el millor lambda...\")\n",
    "\n",
    "for lmbda in valors_lambda:\n",
    "    encerts = 0\n",
    "    total_frases = 0\n",
    "    \n",
    "    for lang_real, llista_frases_val in dades_val.items():\n",
    "        for frase in llista_frases_val:\n",
    "            total_frases += 1\n",
    "            \n",
    "            # Busquem quin idioma dona la probabilitat més alta\n",
    "            max_prob = -float('inf')\n",
    "            idioma_predit = None\n",
    "            \n",
    "            for lang_model in idiomes:\n",
    "                prob = log_probabilitat_frase(\n",
    "                    frase, \n",
    "                    models_cv[lang_model], \n",
    "                    N_T_cv[lang_model], \n",
    "                    B_global, \n",
    "                    lmbda\n",
    "                )\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    idioma_predit = lang_model\n",
    "            \n",
    "            if idioma_predit == lang_real:\n",
    "                encerts += 1\n",
    "                \n",
    "    accuracy = encerts / total_frases\n",
    "    print(f\"Lambda: {lmbda} -> Accuracy Validació: {accuracy:.4f} ({encerts}/{total_frases})\")\n",
    "    \n",
    "    if accuracy > millor_accuracy:\n",
    "        millor_accuracy = accuracy\n",
    "        millor_lambda = lmbda\n",
    "\n",
    "print(f\"\\nEL MILLOR LAMBDA ÉS: {millor_lambda} amb un accuracy de {millor_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08e8126",
   "metadata": {},
   "source": [
    "## 4. Pas 3: Suavitzat de Lidstone i Càlcul de Probabilitats\n",
    "\n",
    "Per calcular la probabilitat que un text pertanyi a un idioma determinat, utilitzem el model de probabilitat d'n-grames assumint independència condicional (enfocament *Naive Bayes*). Com que el mètode de Màxima Versemblança (MLE) falla en assignar probabilitat zero als trigrammes no observats durant l'entrenament, utilitzem la **Llei de Lidstone**.\n",
    "\n",
    "La probabilitat suavitzada d'un trigramma s'estima com:\n",
    "\n",
    "$$P_{LID}(trig | lang) = \\frac{c(trig) + \\lambda}{N_{lang} + \\lambda \\cdot B}$$\n",
    "\n",
    "### 4.1. Definició i Justificació dels Paràmetres\n",
    "\n",
    "Per garantir que les probabilitats de diferents idiomes siguin justament comparables quan fem l'`argmax`, hem de definir acuradament els elements de la fórmula:\n",
    "\n",
    "* **$N_{lang}$ (Suma de freqüències):** És el nombre total d'aparicions de tots els trigrammes que formen el model d'aquell idioma (després d'aplicar el filtre). Aquest valor és **diferent per a cada idioma**, ja que depèn de la morfologia i la llargada exacta del corpus d'entrenament.\n",
    "* **$B$ (Espai mostral / Vocabulari possible):** Representa el nombre de trigrammes potencialment observables. Si cada idioma tingués la seva pròpia $B$, les probabilitats estarien distribuïdes sobre espais de diferent mida i no es podrien comparar directament. Per això, $B$ és una **constant global** igual per a tots els idiomes, calculada com la unió de tots els trigrammes únics trobats als corpus d'entrenament de totes les llengües.\n",
    "* **$\\lambda$ (Factor de suavitzat):** Determina quanta probabilitat es reserva per als trigrammes desconeguts. Ha de ser un **valor únic i global** per a tots els models. Si utilitzéssim un $\\lambda$ diferent per idioma, estaríem penalitzant de manera asimètrica la troballa de caràcters nous, trencant la justícia del classificador.\n",
    "\n",
    "### 4.2. Optimització de $\\lambda$ amb Validació Creuada (Cross-Validation)\n",
    "\n",
    "Atès que $\\lambda$ no és un valor aleatori, l'optimitzarem empíricament:\n",
    "1. Dividirem el corpus d'entrenament mitjançant *Hold-out Validation* (80% per entrenar, 20% per validar).\n",
    "2. Entrenarem els 6 models amb el 80% de les dades.\n",
    "3. Avaluarem el rendiment (Accuracy) sobre el 20% restant provant una bateria de possibles valors per a $\\lambda$ (des de valors molt petits fins a 1.0).\n",
    "4. Seleccionarem el $\\lambda$ que maximitzi l'exactitud per utilitzar-lo en la prova final (Test Set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df222727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "\n",
    "def obtenir_frases_netes(fitxer):\n",
    "    with open(fitxer, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return [frase for frase in text.split(\"  \") if len(frase.strip()) > 0]\n",
    "\n",
    "# 1. Separació Train/Validació (80/20) i creació de models\n",
    "idiomes = ['deu', 'eng', 'fra', 'ita', 'nld', 'spa']\n",
    "dades_train = {}\n",
    "dades_val = {}\n",
    "models_cv = {} \n",
    "N_T_cv = {}    \n",
    "\n",
    "vocabulari_global_cv = set() # Per estimar la B global\n",
    "\n",
    "for lang in idiomes:\n",
    "    fitxer = f\"{lang}_trn_clean.txt\"\n",
    "    frases = obtenir_frases_netes(fitxer)\n",
    "    \n",
    "    # Punt de tall: 80% entrenament, 20% validació\n",
    "    tall = int(len(frases) * 0.8)\n",
    "    dades_train[lang] = \"  \" + \"  \".join(frases[:tall]) + \"  \"\n",
    "    dades_val[lang] = frases[tall:] \n",
    "    \n",
    "    # Creem el model NLTK per al 80%\n",
    "    finder = TrigramCollocationFinder.from_words(dades_train[lang])\n",
    "    finder.apply_freq_filter(5)\n",
    "    model = finder.ngram_fd\n",
    "    \n",
    "    models_cv[lang] = model\n",
    "    N_T_cv[lang] = sum(model.values())\n",
    "    \n",
    "    for trigramma in model.keys():\n",
    "        vocabulari_global_cv.add(trigramma)\n",
    "\n",
    "B_global = len(vocabulari_global_cv)\n",
    "print(f\"Mida del vocabulari global estimat (B): {B_global} trigrammes únics.\\n\")\n",
    "\n",
    "def log_probabilitat_frase(frase, model_lang, N_lang, B_glob, lmbda):\n",
    "    finder = TrigramCollocationFinder.from_words(\"  \" + frase + \"  \")\n",
    "    trigs_frase = finder.ngram_fd\n",
    "    \n",
    "    log_p = 0.0\n",
    "    for trig, freq in trigs_frase.items():\n",
    "        count_train = model_lang.get(trig, 0)\n",
    "        p_lidstone = (count_train + lmbda) / (N_lang + lmbda * B_glob)\n",
    "        log_p += freq * math.log(p_lidstone)\n",
    "        \n",
    "    return log_p\n",
    "\n",
    "# 3. Optimització de Lambda amb un ventall més ampli\n",
    "# Hem afegit valors intermedis per trobar un òptim més ajustat\n",
    "valors_lambda = [0.001, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "millor_lambda = None\n",
    "millor_accuracy = 0.0\n",
    "\n",
    "print(\"Iniciant Validació Creuada (80/20)...\")\n",
    "\n",
    "for lmbda in valors_lambda:\n",
    "    encerts = 0\n",
    "    total_frases = 0\n",
    "    \n",
    "    for lang_real, llista_frases_val in dades_val.items():\n",
    "        for frase in llista_frases_val:\n",
    "            total_frases += 1\n",
    "            \n",
    "            max_prob = -float('inf')\n",
    "            idioma_predit = None\n",
    "            \n",
    "            for lang_model in idiomes:\n",
    "                prob = log_probabilitat_frase(\n",
    "                    frase, \n",
    "                    models_cv[lang_model], \n",
    "                    N_T_cv[lang_model], \n",
    "                    B_global, \n",
    "                    lmbda\n",
    "                )\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    idioma_predit = lang_model\n",
    "            \n",
    "            if idioma_predit == lang_real:\n",
    "                encerts += 1\n",
    "                \n",
    "    accuracy = encerts / total_frases\n",
    "    print(f\"Lambda: {lmbda:5.3f} -> Accuracy Validació: {accuracy:.4f} ({encerts}/{total_frases})\")\n",
    "    \n",
    "    if accuracy > millor_accuracy:\n",
    "        millor_accuracy = accuracy\n",
    "        millor_lambda = lmbda\n",
    "\n",
    "print(f\"\\nEL MILLOR LAMBDA ÉS: {millor_lambda} amb un accuracy de {millor_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd511114",
   "metadata": {},
   "source": [
    "## 4. Pas 3: Suavitzat de Lidstone i Càlcul de Probabilitats\n",
    "\n",
    "El mètode de Màxima Versemblança (MLE) falla perquè assigna una probabilitat de zero als trigrammes no observats durant l'entrenament, la qual cosa anul·la la probabilitat de tota la frase. Per evitar-ho, utilitzem una tècnica de suavitzat, concretament la **Llei de Lidstone**.\n",
    "\n",
    "[cite_start]La fórmula per estimar la probabilitat d'un trigramma $e_j$ en un corpus d'entrenament $T$ és:\n",
    "\n",
    "$$P^T(e_j) \\approx P_{LID}^T(e_j) = \\frac{c_T(e_j) + \\lambda}{N_T + \\lambda B}$$\n",
    "\n",
    "On:\n",
    "* **$c_T(e_j)$**: Freqüència del trigramma en el model d'entrenament (després del filtre de freq. $\\ge 5$).\n",
    "* **$N_T$**: Suma total de les freqüències de tots els trigrammes del model d'entrenament d'aquell idioma (després del filtre).\n",
    "* **$\\lambda$**: Paràmetre de suavitzat constant que trobarem mitjançant validació creuada.\n",
    "* **$B$**: L'espai mostral estimat (vocabulari). Tal com indica la teoria, per fer una bona estimació de totes les combinacions observables, $B$ es calcula sumant **tots els trigrammes únics observats abans d'aplicar el filtre**. $B$ és un valor global igual per a tots els models per garantir que les probabilitats siguin matemàticament comparables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e52d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "\n",
    "def obtenir_frases_netes(fitxer):\n",
    "    with open(fitxer, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return [frase for frase in text.split(\"  \") if len(frase.strip()) > 0]\n",
    "\n",
    "# 1. Separació Train/Validació (80/20) i creació de models\n",
    "idiomes = ['deu', 'eng', 'fra', 'ita', 'nld', 'spa']\n",
    "dades_train = {}\n",
    "dades_val = {}\n",
    "models_cv = {} \n",
    "N_T_cv = {}    \n",
    "\n",
    "vocabulari_global_cv = set() # Per estimar la B global amb TOT el vist\n",
    "\n",
    "for lang in idiomes:\n",
    "    fitxer = f\"{lang}_trn_clean.txt\"\n",
    "    frases = obtenir_frases_netes(fitxer)\n",
    "    \n",
    "    # Punt de tall: 80% entrenament, 20% validació\n",
    "    tall = int(len(frases) * 0.8)\n",
    "    dades_train[lang] = \"  \" + \"  \".join(frases[:tall]) + \"  \"\n",
    "    dades_val[lang] = frases[tall:] \n",
    "    \n",
    "    # Generem els trigrammes NLTK per al 80%\n",
    "    finder = TrigramCollocationFinder.from_words(dades_train[lang])\n",
    "    \n",
    "    # CANVI IMPORTANT: Afegim TOTS els trigrammes al vocabulari global ABANS de filtrar\n",
    "    for trigramma in finder.ngram_fd.keys():\n",
    "        vocabulari_global_cv.add(trigramma)\n",
    "        \n",
    "    # Ara sí, apliquem el filtre de classe (freqüència >= 5) pel model\n",
    "    finder.apply_freq_filter(5)\n",
    "    model = finder.ngram_fd\n",
    "    \n",
    "    # Guardem el model net i la N_T per aquest idioma\n",
    "    models_cv[lang] = model\n",
    "    N_T_cv[lang] = sum(model.values())\n",
    "\n",
    "# Calculem la B real i global\n",
    "B_global = len(vocabulari_global_cv)\n",
    "print(f\"Mida del vocabulari global estimat (B) ABANS de filtrar: {B_global} trigrammes únics.\\n\")\n",
    "\n",
    "def log_probabilitat_frase(frase, model_lang, N_lang, B_glob, lmbda):\n",
    "    finder = TrigramCollocationFinder.from_words(\"  \" + frase + \"  \")\n",
    "    trigs_frase = finder.ngram_fd\n",
    "    \n",
    "    log_p = 0.0\n",
    "    for trig, freq in trigs_frase.items():\n",
    "        count_train = model_lang.get(trig, 0)\n",
    "        p_lidstone = (count_train + lmbda) / (N_lang + lmbda * B_glob)\n",
    "        log_p += freq * math.log(p_lidstone)\n",
    "        \n",
    "    return log_p\n",
    "\n",
    "# 3. Optimització de Lambda \n",
    "valors_lambda = [0.001, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "millor_lambda = None\n",
    "millor_accuracy = 0.0\n",
    "\n",
    "print(\"Iniciant Validació Creuada (80/20)...\")\n",
    "\n",
    "for lmbda in valors_lambda:\n",
    "    encerts = 0\n",
    "    total_frases = 0\n",
    "    \n",
    "    for lang_real, llista_frases_val in dades_val.items():\n",
    "        for frase in llista_frases_val:\n",
    "            total_frases += 1\n",
    "            \n",
    "            max_prob = -float('inf')\n",
    "            idioma_predit = None\n",
    "            \n",
    "            for lang_model in idiomes:\n",
    "                prob = log_probabilitat_frase(\n",
    "                    frase, \n",
    "                    models_cv[lang_model], \n",
    "                    N_T_cv[lang_model], \n",
    "                    B_global, \n",
    "                    lmbda\n",
    "                )\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    idioma_predit = lang_model\n",
    "            \n",
    "            if idioma_predit == lang_real:\n",
    "                encerts += 1\n",
    "                \n",
    "    accuracy = encerts / total_frases\n",
    "    print(f\"Lambda: {lmbda:5.3f} -> Accuracy Validació: {accuracy:.4f} ({encerts}/{total_frases})\")\n",
    "    \n",
    "    if accuracy > millor_accuracy:\n",
    "        millor_accuracy = accuracy\n",
    "        millor_lambda = lmbda\n",
    "\n",
    "print(f\"\\nEL MILLOR LAMBDA ÉS: {millor_lambda} amb un accuracy de {millor_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd451f",
   "metadata": {},
   "source": [
    "fer mes smoothing\n",
    "- absolute discounting\n",
    "- interpolation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
